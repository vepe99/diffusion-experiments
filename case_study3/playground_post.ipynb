{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "import re\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bayesflow as bf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import colorcet as cc\n",
    "\n",
    "from FyeldGenerator import generate_field\n",
    "from resnet import ResNetSummary"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def generate_power_spectrum(alpha, scale):\n",
    "    def power_spectrum(k):\n",
    "        base = np.power(k, -alpha) * scale**2\n",
    "        return base\n",
    "\n",
    "    return power_spectrum\n",
    "\n",
    "\n",
    "def distribution(shape=(128, 128)):\n",
    "    a = np.random.normal(loc=0, scale=1., size=shape)\n",
    "    b = np.random.normal(loc=0, scale=1., size=shape)\n",
    "    return a + 1j * b"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "shape = (128, 128)\n",
    "n_examples = 5\n",
    "alphas = np.linspace(2, 5, n_examples)\n",
    "spectra = [generate_power_spectrum(alpha, 1) for alpha in alphas]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def plot_distribution(shape=(128, 128)):\n",
    "    rng = np.random.default_rng(seed=42)\n",
    "    a = rng.normal(loc=0, scale=1., size=shape)\n",
    "    b = rng.normal(loc=0, scale=1., size=shape)\n",
    "    return a + 1j * b\n",
    "fig, axs = plt.subplots(1, n_examples, figsize=(n_examples * 3, 4))\n",
    "\n",
    "for power_spectrum, alpha, ax in zip(spectra, alphas, axs):\n",
    "    field = generate_field(plot_distribution, power_spectrum, shape)\n",
    "    max_magnitude = np.max(np.abs(field))\n",
    "    # cc.cm.CET_D1A, cc.cm.coolwarm, \"seismic\", cc.cm.CET_R3\n",
    "    ax.imshow(field, cmap=cc.cm.coolwarm, vmin=-max_magnitude, vmax=max_magnitude)\n",
    "    ax.set_title(f\"$\\\\alpha={alpha:.2f}$\")\n",
    "    ax.set_axis_off()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "rng = np.random.default_rng(seed=42)\n",
    "\n",
    "\n",
    "def prior():\n",
    "    return {\"log_std\": rng.normal(scale=0.3), \"alpha\": rng.normal(loc=3, scale=0.5)}\n",
    "\n",
    "\n",
    "def likelihood(log_std, alpha):\n",
    "    field = generate_field(\n",
    "        distribution, generate_power_spectrum(alpha, np.exp(log_std)), shape\n",
    "    )\n",
    "\n",
    "    return {\"field\": field[..., None]}\n",
    "\n",
    "\n",
    "simulator = bf.make_simulator([prior, likelihood])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "training_data = simulator.sample(5000)\n",
    "validation_data = simulator.sample(500)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "summary_network = ResNetSummary(\n",
    "    summary_dim=8, \n",
    "    widths=[16, 32],\n",
    "    use_batch_norm=False,\n",
    "    dropout=0.0\n",
    ")\n",
    "\n",
    "inference_network = bf.networks.FlowMatching(subnet_kwargs={\"widths\": 3*(32,), \"dropout\": 0.0})\n",
    "\n",
    "workflow = bf.workflows.BasicWorkflow(\n",
    "    #simulator=simulator,\n",
    "    summary_network=summary_network,\n",
    "    inference_network=inference_network,\n",
    "    inference_variables=[\"log_std\", \"alpha\"],\n",
    "    summary_variables=[\"field\"],\n",
    "    standardize=\"summary_variables\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "workflow.approximator.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "history = workflow.fit_offline(\n",
    "    data=training_data,\n",
    "    epochs=100,\n",
    "    validation_data=validation_data,\n",
    "    batch_size=32,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "f = bf.diagnostics.plots.loss(history)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "small_training_data = {k: v[:100] for k,v in training_data.items()}\n",
    "test_data = validation_data\n",
    "workflow.plot_custom_diagnostics(\n",
    "    test_data=test_data,\n",
    "    plot_fns={\n",
    "        \"recovery\": bf.diagnostics.recovery,\n",
    "        \"calibration\": bf.diagnostics.calibration_ecdf,\n",
    "    },\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "workflow.approximator.summary()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Evaluations"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "checkpoint_path = \"flow_matching/NPE/checkpoints/8_shape_config_8_16.keras\"\n",
    "model = keras.saving.load_model(checkpoint_path)\n",
    "model.summary()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "models = [\n",
    "    \"consistency_model\",\n",
    "    \"diffusion_edm_vp\",\n",
    "    \"flow_matching\",\n",
    "]\n",
    "scales = [2**n for n in range(3, 9)]\n",
    "target = \"NPE\"\n",
    "model_configs = [\"8_16\", \"32_64_128_256\"]\n",
    "checkpoint_paths = [\n",
    "    f\"{model}/{target}/checkpoints/{scale}_shape_config_{scale}.keras\"\n",
    "    for model in models\n",
    "    for scale in scales\n",
    "]\n",
    "print(checkpoint_paths)\n",
    "numbers_paths = [\n",
    "    f\"{model}/{target}/numbers_{mode}_{scale}_shape_config_{scale}.npz\"\n",
    "    for model in models\n",
    "    for scale in scales\n",
    "    for mode in [\"train\", \"validation\"]\n",
    "]\n",
    "print(numbers_paths)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "z = np.load(numbers_paths[0], allow_pickle=True)\n",
    "for k, v in z.items():\n",
    "    print(k, v)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# numbers_paths = [...]  # your list from above\n",
    "_rx = re.compile(r\"numbers_(train|validation)_(\\d+)_\", re.IGNORECASE)\n",
    "\n",
    "def parse_model_mode_scale(p: str):\n",
    "    model = p.split(\"/\", 1)[0]\n",
    "    m = _rx.search(os.path.basename(p))\n",
    "    if not m:\n",
    "        raise ValueError(f\"Could not parse mode/scale from {p}\")\n",
    "    mode = m.group(1).lower()\n",
    "    scale = int(m.group(2))\n",
    "    return model, mode, scale\n",
    "\n",
    "def row_from_npz(p):\n",
    "    z = np.load(p, allow_pickle=True)\n",
    "    model, mode, scale = parse_model_mode_scale(p)\n",
    "    row = {\"model\": model, \"mode\": mode, \"scale\": scale}\n",
    "    # collect metrics for both variables by name (alpha, log_std)\n",
    "    for metric in (\"nrmse\", \"ce\", \"clg\"):\n",
    "        vals = z[f\"{metric}_values\"]\n",
    "        names = z[f\"{metric}_names\"]\n",
    "        for name, val in zip(names.tolist(), vals.tolist()):\n",
    "            row[f\"{metric}_{name}\"] = float(val)\n",
    "    return row\n",
    "\n",
    "rows = [row_from_npz(p) for p in numbers_paths]\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# optional: rename clg_* -> log_gamma_* for readability\n",
    "df = df.rename(columns=lambda c: c.replace(\"clg_\", \"log_gamma_\"))\n",
    "\n",
    "wanted_cols = [\n",
    "    \"model\", \"mode\", \"scale\",\n",
    "    \"nrmse_alpha\", \"nrmse_log_std\",\n",
    "    \"ce_alpha\", \"ce_log_std\",\n",
    "    \"log_gamma_alpha\", \"log_gamma_log_std\",\n",
    "]\n",
    "# Some files may miss a metric â†’ fill missing columns with NaN\n",
    "for c in wanted_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = np.nan\n",
    "\n",
    "# 4) nice sort (Train first, then Validation, by scale)\n",
    "mode_order = {\"train\": 0, \"validation\": 1}\n",
    "df[\"_mode_order\"] = df[\"mode\"].map(mode_order).fillna(99)\n",
    "df = (df[wanted_cols]\n",
    "      .assign(_mode_order=df[\"_mode_order\"])\n",
    "      .sort_values([\"model\", \"_mode_order\", \"scale\"])\n",
    "      .drop(columns=\"_mode_order\")\n",
    "      .reset_index(drop=True))\n",
    "\n",
    "print(df)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# df columns: model, mode, scale,\n",
    "#   nrmse_alpha, nrmse_log_std, ce_alpha, ce_log_std, log_gamma_alpha, log_gamma_log_std\n",
    "\n",
    "# equally spaced x positions, tick labels are the actual scales\n",
    "scales = sorted(df[\"scale\"].unique())\n",
    "pos = np.arange(len(scales))  # 0..n-1 equally spaced\n",
    "\n",
    "# consistent color per model\n",
    "models = list(sorted(df[\"model\"].unique()))\n",
    "cycle_colors = plt.rcParams[\"axes.prop_cycle\"].by_key().get(\"color\", [\"C0\",\"C1\",\"C2\",\"C3\"])\n",
    "color_map = {m: cycle_colors[i % len(cycle_colors)] for i, m in enumerate(models)}\n",
    "\n",
    "# linestyle per mode\n",
    "style_map = {\"train\": \"-.\", \"validation\": \"-\"}\n",
    "\n",
    "def plot_metric(ax, col, title):\n",
    "    for m in models:\n",
    "        for md in (\"validation\", \"train\"):  # order so solid lines (validation) draw first\n",
    "            sub = (\n",
    "                df[(df[\"model\"] == m) & (df[\"mode\"] == md)]\n",
    "                .set_index(\"scale\")\n",
    "                .reindex(scales)      # align to all scales\n",
    "                .sort_index()\n",
    "            )\n",
    "            ax.plot(\n",
    "                pos, sub[col].values,\n",
    "                marker=\"o\",\n",
    "                linestyle=style_map.get(md, \"-\"),\n",
    "                color=color_map[m],\n",
    "                label=f\"{m} ({md})\"\n",
    "            )\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"scale\")\n",
    "    ax.set_ylabel(\"metric\")\n",
    "    ax.set_xticks(pos)\n",
    "    ax.set_xticklabels([str(s) for s in scales])\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(12, 6), sharex=True)\n",
    "\n",
    "# top row: alpha\n",
    "plot_metric(axes[0, 0], \"nrmse_alpha\",       \"NRMSE (alpha)\")\n",
    "plot_metric(axes[0, 1], \"ce_alpha\",          \"Calibration Error (alpha)\")\n",
    "plot_metric(axes[0, 2], \"log_gamma_alpha\",   \"Log Gamma (alpha)\")\n",
    "\n",
    "# bottom row: log_std\n",
    "plot_metric(axes[1, 0], \"nrmse_log_std\",     \"NRMSE (log_std)\")\n",
    "plot_metric(axes[1, 1], \"ce_log_std\",        \"Calibration Error (log_std)\")\n",
    "plot_metric(axes[1, 2], \"log_gamma_log_std\", \"Log Gamma (log_std)\")\n",
    "\n",
    "# legends: one for models (colors), one for modes (linestyles)\n",
    "model_handles = [Line2D([0], [0], color=color_map[m], lw=2, label=m) for m in models]\n",
    "mode_handles  = [Line2D([0], [0], color=\"black\", lw=2, linestyle=style_map[k], label=k)\n",
    "                 for k in (\"validation\", \"train\")]\n",
    "\n",
    "axes[0, 0].legend(handles=model_handles, title=\"model\", loc=\"best\")\n",
    "axes[1, 0].legend(handles=mode_handles,  title=\"mode\",  loc=\"best\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
