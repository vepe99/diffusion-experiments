{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Case Study: Compositional Inference for a Drift Diffusion Model",
   "id": "f0f59c3bce4dc698"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Consider a decision task in which participants are presented with sequences of letters and asked\n",
    "to differentiate between words and non-words (i.e., a lexical decision task). The Diffusion Decision Model (DDM;\n",
    "e.g., Ratcliff et al., 2016) simulataneously models this binary decision and the response time via a continuous evidence\n",
    "accumulation process: After an initial non-decision time t0, evidence accumulates following a noisy diffusion process\n",
    "with a certain drift rate ν, starting from a point β, until one of two decision thresholds {0,α}corresponding to the two\n",
    "choices is hit.\n",
    "\n",
    "\\begin{align*}\n",
    "\\nu_j\\sim\\mathcal{N}(0.5,\\exp(-1)) \\\\\n",
    "\\log \\alpha_j\\sim\\mathcal{N}(0,\\exp(-3)) \\\\\n",
    "\\log t_{0,j}\\sim\\mathcal{N}(-1,\\exp(-1)) \\\\\n",
    "\\beta_j\\sim\\operatorname{Beta}(a=50,b=50) \\\\\n",
    "y_j\\sim \\operatorname{DDM}(\\nu_j,\\alpha_j,t_{0,j},\\beta_j)\n",
    "\\end{align*}\n",
    "$\\beta_\\text{raw}$ is a transformed unbounded variable that is transformed to $\\beta$ via the beta inverse CDF.\n"
   ],
   "id": "87ef9510c29662c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "else:\n",
    "    print(f\"Using '{os.environ['KERAS_BACKEND']}' backend\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import bayesflow as bf\n",
    "\n",
    "from ddm_simulator import simulate_ddm, beta_from_normal\n",
    "\n",
    "problem_name = \"compositional_case_study\"\n",
    "storage = '' #f'plots/{problem_name}/'\n",
    "n_jobs = 10 #int(os.environ.get('SLURM_CPUS_PER_TASK', 1))"
   ],
   "id": "86cd4e0b9f89165b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_names = ['nu', 'log_alpha', 'log_t0', 'beta_raw']\n",
    "pretty_param_names = [r'$\\nu$', r'$\\log \\alpha$', r'$\\log t_0$', r'$\\beta_\\text{raw}$']\n",
    "pretty_param_names_p = [r'$\\nu_p$', r'$\\log \\alpha_p$', r'$\\log t_{0,p}$', r'$\\beta_p$']\n",
    "num_training_batches = 256\n",
    "num_validation_sets = 300\n",
    "batch_size = 128\n",
    "epochs = 1000"
   ],
   "id": "2fd187d5b89d6e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Priors\n",
    "# ---------------------------\n",
    "def sample_priors():\n",
    "    # Subject level\n",
    "    nu = np.random.normal(0.5, np.exp(-1.0))\n",
    "    log_alpha = np.random.normal(0.0, np.exp(-3.0))\n",
    "    log_t0 = np.random.normal(-1.0, np.exp(-1.0))\n",
    "\n",
    "    #beta = np.random.beta(a=50, b=50)\n",
    "    beta_raw = np.random.normal(0.0, 1.0)\n",
    "    beta = beta_from_normal(beta_raw, a=50, b=50)\n",
    "\n",
    "    return {\n",
    "        \"nu\": nu,\n",
    "        \"log_alpha\": log_alpha,\n",
    "        \"alpha\": np.exp(log_alpha),\n",
    "        \"log_t0\": log_t0,\n",
    "        \"t0\": np.exp(log_t0),\n",
    "        \"beta_raw\": beta_raw,\n",
    "        \"beta\": beta,\n",
    "    }\n",
    "\n",
    "def score_log_norm(x, m, s):\n",
    "    return -(x - m) / s**2\n",
    "\n",
    "def prior_score(x: dict):\n",
    "    nu = x[\"nu\"]\n",
    "    log_alpha = x[\"log_alpha\"]\n",
    "    log_t0 = x[\"log_t0\"]\n",
    "    beta_raw = x[\"beta_raw\"]\n",
    "\n",
    "    parts = {\n",
    "        \"nu\": score_log_norm(nu, m=0.5, s=np.exp(-1.0)),\n",
    "        \"log_alpha\": score_log_norm(log_alpha, m=0.0, s=np.exp(-3.0)),\n",
    "        \"log_t0\": score_log_norm(log_t0, m=-1.0, s=np.exp(-1.0)),\n",
    "        \"beta_raw\":  score_log_norm(beta_raw, m=0.0, s=1.0)\n",
    "    }\n",
    "    return parts\n",
    "\n",
    "simulator = bf.make_simulator([sample_priors, simulate_ddm])\n",
    "print(simulator.sample(1)['sim_data'].shape)"
   ],
   "id": "66179c1fa0cbd4e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "few_trials = 5\n",
    "training_data_trials = None #simulator.sample_parallel((num_training_batches * batch_size), n_trials=few_trials)\n",
    "validation_data_trials = simulator.sample_parallel(num_validation_sets, n_trials=few_trials)"
   ],
   "id": "fef31a3d6077808",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .to_array()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .concatenate(param_names, into=\"inference_variables\")\n",
    "    .rename(\"sim_data\", \"summary_variables\")\n",
    ")"
   ],
   "id": "7b877a3b3d13718e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check how the distributions look like\n",
    "test_params = adapter.forward(validation_data_trials)['inference_variables']\n",
    "\n",
    "n_rows = len(param_names) // 4\n",
    "n_cols = int(np.ceil(len(param_names) / n_rows))\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(2*n_cols, 2*n_rows), layout='constrained')\n",
    "ax = ax.flatten()\n",
    "for i, name in enumerate(pretty_param_names):\n",
    "    samples = test_params[:, i]\n",
    "    ax[i].hist(samples, density=True)\n",
    "    ax[i].set_title(name)\n",
    "plt.show()\n",
    "\n",
    "print(test_params.shape)"
   ],
   "id": "590b7586c13b1a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check how the data distribution looks like\n",
    "test_data = adapter.forward(validation_data_trials)['summary_variables']\n",
    "n_features = test_data.shape[-1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(n_features / 2)), figsize=(8, 4), layout='constrained')\n",
    "ax = ax.flatten()\n",
    "for i in range(n_features):\n",
    "    ax[i].hist(test_data[..., i].flatten(), density=True)\n",
    "plt.show()\n",
    "\n",
    "print(test_data.shape)"
   ],
   "id": "e4ba6641adbf0209",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# No Pooling\n",
    " trained on few trials, compositional inference over trials for the same subject"
   ],
   "id": "aea98f328685db4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "workflow_trials = bf.BasicWorkflow(\n",
    "    adapter=adapter,\n",
    "    summary_network=bf.networks.SetTransformer(summary_dim=16, dropout=0.1),\n",
    "    inference_network=bf.networks.CompositionalDiffusionModel(),\n",
    ")"
   ],
   "id": "71267ef96c8e940b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_path = f'{storage}models/pooling_few_trial.keras'\n",
    "if not os.path.exists(model_path):\n",
    "    history = workflow_trials.fit_offline(\n",
    "        training_data_trials,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_data_trials,\n",
    "        verbose=2,\n",
    "    )\n",
    "    workflow_trials.approximator.save(model_path)\n",
    "else:\n",
    "    workflow_trials.approximator = keras.models.load_model(model_path)"
   ],
   "id": "a161f6777e95c1d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics_plots = workflow_trials.plot_default_diagnostics(test_data=validation_data_trials, num_samples=100,\n",
    "                                                             calibration_ecdf_kwargs={\"difference\": True},\n",
    "                                                             variable_names=pretty_param_names)\n",
    "#for k in diagnostics_plots.keys():\n",
    "#    diagnostics_plots[k].savefig(f\"{storage}plots/pooling_few_trial_{k}.png\")"
   ],
   "id": "906e9b9704f52108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ps = workflow_trials.sample(conditions=validation_data_trials, num_samples=100)\n",
    "ps['beta'] = beta_from_normal(ps['beta_raw'], a=50, b=50)\n",
    "ps.pop('beta_raw');"
   ],
   "id": "9b7c441ecc803e96",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=ps,\n",
    "    targets=validation_data_trials,\n",
    "    variable_names=pretty_param_names_p\n",
    ")\n",
    "fig.savefig(f\"{storage}plots/pooling_few_trial_recovery.png\")"
   ],
   "id": "f4f1de50cdaef030",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compositional inference over trials",
   "id": "a7f6461466032a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_trials = 25\n",
    "n_datasets = num_validation_sets\n",
    "test_data_comp_trials = simulator.sample_parallel(n_datasets, n_trials=n_trials)\n",
    "validation_data_trials['sim_data'].shape, test_data_comp_trials['sim_data'].shape"
   ],
   "id": "2454c7c783649d9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('n compositional scores:', n_trials//few_trials)\n",
    "test_posterior_comp_trials = workflow_trials.compositional_sample(\n",
    "    num_samples=100,\n",
    "    conditions={\n",
    "        'sim_data': test_data_comp_trials['sim_data'][:, None].reshape(\n",
    "            n_datasets, n_trials//few_trials, few_trials, 2)\n",
    "    },\n",
    "    compute_prior_score=prior_score,\n",
    "    steps=200,\n",
    "    #corrector_steps=1,\n",
    "    #step_size_factor=0.01,\n",
    "    #compositional_bridge_d1=0.001,\n",
    "    #compositional_bridge_d0=0.01,\n",
    "    mini_batch_size=1\n",
    ")\n",
    "\n",
    "test_posterior_comp_trials['beta'] = beta_from_normal(test_posterior_comp_trials['beta_raw'], a=50, b=50)\n",
    "test_posterior_comp_trials.pop('beta_raw');"
   ],
   "id": "3a042b6f903dc556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=test_posterior_comp_trials,\n",
    "    targets=test_data_comp_trials,\n",
    "    variable_names=pretty_param_names_p\n",
    ")\n",
    "fig.savefig(f\"{storage}plots/pooling_compositional_trials_recovery.png\")\n",
    "\n",
    "fig = bf.diagnostics.calibration_ecdf(\n",
    "    estimates=test_posterior_comp_trials,\n",
    "    targets=test_data_comp_trials,\n",
    "    difference=True,\n",
    "    variable_names=pretty_param_names_p\n",
    ")\n",
    "# fig.savefig(f\"{storage}plots/pooling_compositional_trials_calibration.png\")"
   ],
   "id": "aa3c52e826d229c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Complete Pooling",
   "id": "2477e86b5416d739"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compositional inference over subjects",
   "id": "c45edc6c03428571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "n_subjects = 30\n",
    "n_datasets = num_validation_sets\n",
    "test_data_comp_subjects = simulator.sample_parallel(n_datasets, n_subjects=n_subjects, n_trials=n_trials)\n",
    "validation_data_trials['sim_data'].shape, test_data_comp_subjects['sim_data'].shape"
   ],
   "id": "8a8497f190bb1044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('n compositional scores:', n_subjects*n_trials//few_trials)\n",
    "test_posterior_comp_subjects = workflow_trials.compositional_sample(\n",
    "    num_samples=100,\n",
    "    conditions={\n",
    "        'sim_data': test_data_comp_subjects['sim_data'][:, None].reshape(\n",
    "            n_datasets, n_subjects*n_trials//few_trials, few_trials, 2)\n",
    "    },\n",
    "    compute_prior_score=prior_score,\n",
    "    steps=200,\n",
    "    corrector_steps=1,\n",
    "    #step_size_factor=0.01,\n",
    "    compositional_bridge_d1=0.001,\n",
    "    mini_batch_size=1\n",
    ")\n",
    "test_posterior_comp_subjects['beta'] = beta_from_normal(test_posterior_comp_subjects['beta_raw'], a=50, b=50)\n",
    "test_posterior_comp_subjects.pop('beta_raw');"
   ],
   "id": "e4d0bfc051a29aef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=test_posterior_comp_subjects,\n",
    "    targets=test_data_comp_subjects,\n",
    "    variable_names=pretty_param_names_p\n",
    ")\n",
    "fig.savefig(f\"{storage}plots/complete_pooling_recovery.png\")\n",
    "\n",
    "fig = bf.diagnostics.calibration_ecdf(\n",
    "    estimates=test_posterior_comp_subjects,\n",
    "    targets=test_data_comp_subjects,\n",
    "    difference=True,\n",
    "    variable_names=pretty_param_names_p\n",
    ")\n",
    "# fig.savefig(f\"{storage}plots/complete_pooling_calibration.png\")"
   ],
   "id": "5702f67ea2d79390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "79dececadf6d314a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
