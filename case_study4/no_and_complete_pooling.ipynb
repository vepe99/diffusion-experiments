{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# Case Study: Compositional Inference for a Drift Diffusion Model",
   "id": "f0f59c3bce4dc698"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Consider a decision task in which participants are presented with sequences of letters and asked\n",
    "to differentiate between words and non-words (i.e., a lexical decision task). The Diffusion Decision Model (DDM;\n",
    "e.g., Ratcliff et al., 2016) simulataneously models this binary decision and the response time via a continuous evidence\n",
    "accumulation process: After an initial non-decision time t0, evidence accumulates following a noisy diffusion process\n",
    "with a certain drift rate ν, starting from a point β, until one of two decision thresholds {0,α}corresponding to the two\n",
    "choices is hit.\n",
    "\n",
    "\\begin{align*}\n",
    "\\nu_j\\sim\\mathcal{N}(0.5,\\exp(-1)) \\\\\n",
    "\\log \\alpha_j\\sim\\mathcal{N}(0,\\exp(-3)) \\\\\n",
    "\\log t_{0,j}\\sim\\mathcal{N}(-1,\\exp(-1)) \\\\\n",
    "\\beta_j\\sim\\operatorname{Beta}(a=50,b=50) \\\\\n",
    "y_j\\sim \\operatorname{DDM}(\\nu_j,\\alpha_j,t_{0,j},\\beta_j)\n",
    "\\end{align*}\n",
    "$\\beta_\\text{raw}$ is a transformed unbounded variable that is transformed to $\\beta$ via the beta inverse CDF.\n"
   ],
   "id": "87ef9510c29662c8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "else:\n",
    "    print(f\"Using '{os.environ['KERAS_BACKEND']}' backend\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import keras\n",
    "import bayesflow as bf\n",
    "\n",
    "from ddm_simulator import simulate_ddm, beta_from_normal\n",
    "\n",
    "problem_name = \"compositional_case_study\"\n",
    "storage = '' #f'plots/{problem_name}/'\n",
    "n_jobs = 10 #int(os.environ.get('SLURM_CPUS_PER_TASK', 1))"
   ],
   "id": "86cd4e0b9f89165b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_names = ['nu', 'log_alpha', 'log_t0', 'beta_raw']\n",
    "pretty_param_names = [r'$\\nu$', r'$\\log \\alpha$', r'$\\log t_0$', r'$\\beta_\\text{raw}$']\n",
    "num_training_batches = 256\n",
    "num_validation_sets = 300\n",
    "batch_size = 64\n",
    "epochs = 1000\n",
    "\n",
    "n_trials = 25"
   ],
   "id": "2fd187d5b89d6e6e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# ---------------------------\n",
    "# Priors\n",
    "# ---------------------------\n",
    "def sample_priors():\n",
    "    # Subject level\n",
    "    nu = np.random.normal(0.5, np.exp(-1.0))\n",
    "    log_alpha = np.random.normal(0.0, np.exp(-3.0))\n",
    "    log_t0 = np.random.normal(-1.0, np.exp(-1.0))\n",
    "\n",
    "    #beta = np.random.beta(a=50, b=50)\n",
    "    beta_raw = np.random.normal(0.0, 1.0)\n",
    "    beta = beta_from_normal(beta_raw, a=50, b=50)\n",
    "\n",
    "    return {\n",
    "        \"nu\": nu,\n",
    "        \"log_alpha\": log_alpha,\n",
    "        \"alpha\": np.exp(log_alpha),\n",
    "        \"log_t0\": log_t0,\n",
    "        \"t0\": np.exp(log_t0),\n",
    "        \"beta_raw\": beta_raw,\n",
    "        \"beta\": beta,\n",
    "    }\n",
    "\n",
    "def score_log_norm(x, m, s):\n",
    "    return -(x - m) / s**2\n",
    "\n",
    "def prior_score(x: dict):\n",
    "    nu = x[\"nu\"]\n",
    "    log_alpha = x[\"log_alpha\"]\n",
    "    log_t0 = x[\"log_t0\"]\n",
    "    beta_raw = x[\"beta_raw\"]\n",
    "\n",
    "    parts = {\n",
    "        \"nu\": score_log_norm(nu, m=0.5, s=np.exp(-1.0)),\n",
    "        \"log_alpha\": score_log_norm(log_alpha, m=0.0, s=np.exp(-3.0)),\n",
    "        \"log_t0\": score_log_norm(log_t0, m=-1.0, s=np.exp(-1.0)),\n",
    "        \"beta_raw\":  score_log_norm(beta_raw, m=0.0, s=1.0)\n",
    "    }\n",
    "    return parts\n",
    "\n",
    "simulator = bf.make_simulator([sample_priors, simulate_ddm])\n",
    "print(simulator.sample(1)['sim_data'].shape)"
   ],
   "id": "66179c1fa0cbd4e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if os.path.exists(f\"{storage}validation_data_single_trials.pkl\"):\n",
    "    with open(f'{storage}validation_data_single_trials.pkl', 'rb') as f:\n",
    "        validation_data_trials = pickle.load(f)\n",
    "    with open(f'{storage}validation_data_single_subjects.pkl', 'rb') as f:\n",
    "        validation_data_subjects = pickle.load(f)\n",
    "    try:\n",
    "        with open(f'{storage}training_data_single_trials.pkl', 'rb') as f:\n",
    "            training_data_trials = pickle.load(f)\n",
    "        with open(f'{storage}training_data_single_subjects.pkl', 'rb') as f:\n",
    "            training_data_subjects = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        training_data_trials = None\n",
    "        training_data_subjects = None\n",
    "        print(\"Training data not found\")\n",
    "else:\n",
    "    training_data_trials = simulator.sample_parallel((num_training_batches * batch_size))\n",
    "    validation_data_trials = simulator.sample_parallel(num_validation_sets)\n",
    "\n",
    "    with open(f'{storage}training_data_single_trials.pkl', 'wb') as f:\n",
    "        pickle.dump(training_data_trials, f)\n",
    "    with open(f'{storage}validation_data_single_trials.pkl', 'wb') as f:\n",
    "        pickle.dump(validation_data_trials, f)\n",
    "\n",
    "    training_data_subjects = simulator.sample_parallel((num_training_batches * batch_size), n_trials=n_trials)\n",
    "    validation_data_subjects = simulator.sample_parallel(num_validation_sets, n_trials=n_trials)\n",
    "\n",
    "    with open(f'{storage}validation_data_single_subjects.pkl', 'wb') as f:\n",
    "        pickle.dump(validation_data_subjects, f)\n",
    "    with open(f'{storage}training_data_single_subjects.pkl', 'wb') as f:\n",
    "        pickle.dump(training_data_subjects, f)"
   ],
   "id": "584ce273cb384ce9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .to_array()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .concatenate(param_names, into=\"inference_variables\")\n",
    "    .rename(\"sim_data\", \"inference_conditions\")\n",
    ")"
   ],
   "id": "7b877a3b3d13718e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check how the distributions look like\n",
    "test_params = adapter.forward(validation_data_trials)['inference_variables']\n",
    "#test_params = adapter.forward(validation_data_subjects)['inference_variables']\n",
    "\n",
    "n_rows = len(param_names) // 4\n",
    "n_cols = int(np.ceil(len(param_names) / n_rows))\n",
    "fig, ax = plt.subplots(n_rows, n_cols, figsize=(2*n_cols, 2*n_rows), layout='constrained')\n",
    "ax = ax.flatten()\n",
    "for i, name in enumerate(pretty_param_names):\n",
    "    samples = test_params[:, i]\n",
    "    ax[i].hist(samples, density=True)\n",
    "    ax[i].set_title(name)\n",
    "plt.show()\n",
    "\n",
    "print(test_params.shape)"
   ],
   "id": "590b7586c13b1a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# check how the data distribution looks like (disable nan_to_num in adapter to see nans)\n",
    "#test_data = adapter.forward(validation_data_trials)['inference_conditions']\n",
    "test_data = adapter.forward(validation_data_subjects)['inference_conditions']\n",
    "n_features = test_data.shape[-1]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=2, ncols=int(np.ceil(n_features / 2)), figsize=(8, 4), layout='constrained')\n",
    "ax = ax.flatten()\n",
    "for i in range(n_features):\n",
    "    ax[i].hist(test_data[..., i].flatten(), density=True)\n",
    "plt.show()\n",
    "\n",
    "print(test_data.shape)"
   ],
   "id": "e4ba6641adbf0209",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# No Pooling\n",
    " trained on single trials, compositional inference over trials for the same subject"
   ],
   "id": "aea98f328685db4b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "workflow_trials = bf.BasicWorkflow(\n",
    "    adapter=adapter,\n",
    "    inference_network=bf.networks.DiffusionModel(),\n",
    ")"
   ],
   "id": "71267ef96c8e940b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_path = f'{storage}no_pooling_single_trial.keras'\n",
    "if not os.path.exists(model_path):\n",
    "    history = workflow_trials.fit_offline(\n",
    "        training_data_trials,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_data_trials,\n",
    "    )\n",
    "    workflow_trials.approximator.save(model_path)\n",
    "else:\n",
    "    workflow_trials.approximator = keras.models.load_model(model_path)"
   ],
   "id": "a161f6777e95c1d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics_plots = workflow_trials.plot_default_diagnostics(test_data=validation_data_trials, num_samples=100,\n",
    "                                                             calibration_ecdf_kwargs={\"difference\": True},\n",
    "                                                             variable_names=pretty_param_names)\n",
    "for k in diagnostics_plots.keys():\n",
    "    diagnostics_plots[k].savefig(f\"{storage}no_pooling_single_trial_{k}.png\")"
   ],
   "id": "906e9b9704f52108",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compositional inference over trials",
   "id": "a7f6461466032a2f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_data_comp_trials = simulator.sample_parallel(15, n_trials=5)\n",
    "validation_data_trials['sim_data'].shape, test_data_comp_trials['sim_data'].shape"
   ],
   "id": "2454c7c783649d9b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_posterior_comp_trials = workflow_trials.compositional_sample(num_samples=10,\n",
    "                                                                  conditions={'sim_data': test_data_comp_trials['sim_data']},\n",
    "                                                                  compute_prior_score=prior_score)"
   ],
   "id": "3a042b6f903dc556",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "test_posterior_comp_trials['nu'].shape",
   "id": "ee5e21fa3e797d49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=test_posterior_comp_trials,\n",
    "    targets=test_data_comp_trials,\n",
    "    variable_names=pretty_param_names\n",
    ")\n",
    "fig.savefig(f\"{storage}no_pooling_compositional_trials_recovery.png\")\n",
    "\n",
    "fig = bf.diagnostics.calibration_ecdf(\n",
    "    estimates=test_posterior_comp_trials,\n",
    "    targets=test_data_comp_trials,\n",
    "    difference=True,\n",
    "    variable_names=pretty_param_names\n",
    ")\n",
    "fig.savefig(f\"{storage}no_pooling_compositional_trials_calibration.png\")"
   ],
   "id": "aa3c52e826d229c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Training on multiple trials per subject\n",
    "trained on single subjects (multiple trials)"
   ],
   "id": "35ddd8004d312b1a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "adapter_subjects = (\n",
    "    bf.adapters.Adapter()\n",
    "    .to_array()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .concatenate(param_names, into=\"inference_variables\")\n",
    "    .rename(\"sim_data\", \"summary_variables\")\n",
    ")"
   ],
   "id": "a58b017e85c4c8c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "workflow_subjects = bf.BasicWorkflow(\n",
    "    adapter=adapter_subjects,\n",
    "    summary_network=bf.networks.SetTransformer(summary_dim=16, dropout=0.1),\n",
    "    inference_network=bf.networks.DiffusionModel(),\n",
    ")"
   ],
   "id": "f608f6c3e91eb5f3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_path = f'{storage}no_pooling_single_subject.keras'\n",
    "if not os.path.exists(model_path):\n",
    "    history = workflow_subjects.fit_offline(\n",
    "        training_data_subjects,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=validation_data_subjects,\n",
    "    )\n",
    "    workflow_subjects.approximator.save(model_path)\n",
    "else:\n",
    "    workflow_subjects.approximator = keras.models.load_model(model_path)"
   ],
   "id": "74f75a248874eb15",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics_plots = workflow_subjects.plot_default_diagnostics(test_data=validation_data_subjects, num_samples=100,\n",
    "                                                               calibration_ecdf_kwargs={\"difference\": True},\n",
    "                                                               variable_names=pretty_param_names)\n",
    "for k in diagnostics_plots.keys():\n",
    "    diagnostics_plots[k].savefig(f\"{storage}no_pooling_single_subject_{k}.png\")"
   ],
   "id": "527d5e311afdfd04",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Complete Pooling",
   "id": "2477e86b5416d739"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compositional inference over trials and subjects",
   "id": "8d7eb0726bd9b0b0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_data_comp_subjects_trials = simulator.sample_parallel(15, n_subjects=10, n_trials=5)\n",
    "test_data_comp_subjects_trials['sim_data'] = test_data_comp_subjects_trials['sim_data'].reshape(15, 10*5, 2)\n",
    "validation_data_trials['sim_data'].shape, test_data_comp_subjects_trials['sim_data'].shape"
   ],
   "id": "1b3f18f9bac1ce3d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_posterior_comp_subjects_trials = workflow_trials.compositional_sample(num_samples=10,\n",
    "                                                                           conditions={'sim_data': test_data_comp_subjects_trials['sim_data']},\n",
    "                                                                           compute_prior_score=prior_score)"
   ],
   "id": "fd6d69f6de6f6eb6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=test_posterior_comp_subjects_trials,\n",
    "    targets=test_data_comp_subjects_trials,\n",
    "    variable_names=pretty_param_names\n",
    ")\n",
    "fig.savefig(f\"{storage}no_pooling_compositional_subjects_trials_recovery.png\")\n",
    "\n",
    "fig = bf.diagnostics.calibration_ecdf(\n",
    "    estimates=test_posterior_comp_subjects_trials,\n",
    "    targets=test_data_comp_subjects_trials,\n",
    "    difference=True,\n",
    "    variable_names=pretty_param_names\n",
    ")\n",
    "fig.savefig(f\"{storage}no_pooling_compositional_subjects_trials_calibration.png\")"
   ],
   "id": "d776132d315e109f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Compositional inference over subjects",
   "id": "c45edc6c03428571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_data_comp_subjects = simulator.sample_parallel(15, n_subjects=10, n_trials=n_trials)\n",
    "validation_data_subjects['sim_data'].shape, test_data_comp_subjects['sim_data'].shape"
   ],
   "id": "8a8497f190bb1044",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "test_posterior_comp_subjects = workflow_subjects.compositional_sample(num_samples=10,\n",
    "                                                                      conditions={'sim_data': test_data_comp_subjects['sim_data']},\n",
    "                                                                      compute_prior_score=prior_score)"
   ],
   "id": "e4d0bfc051a29aef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=test_posterior_comp_subjects,\n",
    "    targets=test_data_comp_subjects,\n",
    "    variable_names=pretty_param_names\n",
    ")\n",
    "fig.savefig(f\"{storage}complete_pooling_compositional_subjects_recovery.png\")\n",
    "\n",
    "fig = bf.diagnostics.calibration_ecdf(\n",
    "    estimates=test_posterior_comp_subjects,\n",
    "    targets=test_data_comp_subjects,\n",
    "    difference=True,\n",
    "    variable_names=pretty_param_names\n",
    ")\n",
    "fig.savefig(f\"{storage}complete_pooling_compositional_subjects_calibration.png\")"
   ],
   "id": "5702f67ea2d79390",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "79dececadf6d314a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
