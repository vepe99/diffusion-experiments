{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "# PEtab benchmark model with BayesFlow",
   "id": "f2db3aaca617dd83"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# pip install git+https://github.com/Benchmarking-Initiative/Benchmark-Models-PEtab.git@master#subdirectory=src/python\n",
    "# pypesto, amici, petab, fides, joblib"
   ],
   "id": "c4c3a5bf38839491",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:37.470265Z",
     "start_time": "2025-09-22T08:36:33.873252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "else:\n",
    "    print(f\"Using '{os.environ['KERAS_BACKEND']}' backend\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "import pickle\n",
    "from joblib import Parallel, delayed\n",
    "from typing import Union\n",
    "from collections import defaultdict\n",
    "\n",
    "import benchmark_models_petab as benchmark_models\n",
    "import petab\n",
    "import pypesto.optimize as optimize\n",
    "import pypesto.sample as sample\n",
    "import pypesto.petab\n",
    "import pypesto.visualize as visualize\n",
    "from pypesto.visualize.model_fit import visualize_optimized_model_fit\n",
    "from scipy import stats\n",
    "\n",
    "import keras\n",
    "import bayesflow as bf\n",
    "\n",
    "import amici\n",
    "import logging\n",
    "amici.swig_wrappers.logger.setLevel(logging.CRITICAL)\n",
    "pypesto.logging.log(level=logging.ERROR, name=\"pypesto.petab\", console=True)\n",
    "\n",
    "from petab_helper import scale_values, values_to_linear_scale, amici_pred_to_array, apply_noise_to_data\n",
    "\n",
    "# print all model names\n",
    "print(benchmark_models.MODELS)"
   ],
   "id": "f7d1d9565944bee9",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:2025-09-22 10:36:37,415:jax._src.xla_bridge:822: Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/opt/homebrew/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file)\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INTERNAL: Failed to open libtpu.so: dlopen(libtpu.so, 0x0001): tried: 'libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OSlibtpu.so' (no such file), '/opt/homebrew/lib/libtpu.so' (no such file), '/System/Volumes/Preboot/Cryptexes/OS/opt/homebrew/lib/libtpu.so' (no such file), '/usr/lib/libtpu.so' (no such file, not in dyld cache), 'libtpu.so' (no such file)\n",
      "INFO:bayesflow:Using backend 'jax'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Alkan_SciSignal2018', 'Armistead_CellDeathDis2024', 'Bachmann_MSB2011', 'Beer_MolBioSystems2014', 'Bertozzi_PNAS2020', 'Blasi_CellSystems2016', 'Boehm_JProteomeRes2014', 'Borghans_BiophysChem1997', 'Brannmark_JBC2010', 'Bruno_JExpBot2016', 'Chen_MSB2009', 'Crauste_CellSystems2017', 'Elowitz_Nature2000', 'Fiedler_BMCSystBiol2016', 'Froehlich_CellSystems2018', 'Fujita_SciSignal2010', 'Giordano_Nature2020', 'Isensee_JCB2018', 'Lang_PLOSComputBiol2024', 'Laske_PLOSComputBiol2019', 'Lucarelli_CellSystems2018', 'Okuonghae_ChaosSolitonsFractals2020', 'Oliveira_NatCommun2021', 'Perelson_Science1996', 'Rahman_MBS2016', 'Raia_CancerResearch2011', 'Raimundez_PCB2020', 'SalazarCavazos_MBoC2020', 'Schwen_PONE2014', 'Smith_BMCSystBiol2013', 'Sneyd_PNAS2002', 'Weber_BMC2015', 'Zhao_QuantBiol2020', 'Zheng_PNAS2012']\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:51.476631Z",
     "start_time": "2025-09-22T08:36:37.475848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# generate petab problem\n",
    "#job_id = int(os.environ.get('SLURM_ARRAY_TASK_ID', 0))\n",
    "n_cpus = 10 #int(os.environ.get('SLURM_CPUS_PER_TASK', 1))\n",
    "problem_name = \"Beer_MolBioSystems2014\" #\"Raimundez_PCB2020\", \"Beer_MolBioSystems2014\", \"Boehm_JProteomeRes2014\"\n",
    "storage = '' # f'plots/{problem_name}/'\n",
    "petab_problem = benchmark_models.get_problem(problem_name)\n",
    "\n",
    "# decrease upper bounds for offset, scaling and noise parameters\n",
    "scale_params_id = [name for name in petab_problem.parameter_df.index.values if name[:6] == 'offset' or name[:5] == 'scale']\n",
    "petab_problem.parameter_df.loc[scale_params_id, 'upperBound'] = 100  # instead of 1000\n",
    "sd_params_id = [name for name in petab_problem.parameter_df.index.values if name[:3] == 'sd_']\n",
    "petab_problem.parameter_df.loc[sd_params_id, 'upperBound'] = 10  # instead of 1000\n",
    "\n",
    "if problem_name == \"Raimundez_PCB2020\":\n",
    "    # Elba added normal priors for the scaling params\n",
    "    scale_params_id = [name for name in petab_problem.parameter_df.index.values if name[:2] == 's_']\n",
    "    petab_problem.parameter_df.loc[scale_params_id, 'objectivePriorType'] = \"normal\"\n",
    "    petab_problem.parameter_df.loc[scale_params_id, 'objectivePriorParameters'] = \"1;10\"\n",
    "    petab_problem.parameter_df.loc[scale_params_id, 'parameterScale'] = \"lin\"\n",
    "\n",
    "# add normal prior (on scale) around real parameters values\n",
    "real_data_params = petab_problem.parameter_df.nominalValue\n",
    "std = 0.5\n",
    "for i in real_data_params.index:\n",
    "    if petab_problem.parameter_df.loc[i, 'estimate'] == 0:\n",
    "        continue\n",
    "    # set prior mean depending on scale\n",
    "    mean = scale_values(real_data_params.loc[i], petab_problem.parameter_df.loc[i, 'parameterScale'])\n",
    "    if not 'objectivePriorType' in petab_problem.parameter_df or pd.isna(petab_problem.parameter_df.loc[i, 'objectivePriorType']):\n",
    "        petab_problem.parameter_df.loc[i, 'objectivePriorType'] = \"parameterScaleNormal\"\n",
    "        petab_problem.parameter_df.loc[i, 'objectivePriorParameters'] = f\"{mean};{std}\"\n",
    "\n",
    "for i, row in petab_problem.parameter_df.iterrows():\n",
    "    if 'objectivePriorType' in row and not pd.isna(row['objectivePriorType']):\n",
    "        if row['estimate'] == 0:\n",
    "            print(f\"Parameter {i} has a {row['objectivePriorType']} prior but is not estimated, setting to nan\")\n",
    "            petab_problem.parameter_df.loc[i, 'objectivePriorType'] = np.nan\n",
    "        # validate petab problem, if scale for parameter is defined, prior must be on the same scale\n",
    "        if row['parameterScale'] != 'lin' and not row['objectivePriorType'].startswith('parameterScale'):\n",
    "            raise ValueError(f\"Parameter {i} has parameterScale {row['parameterScale']} but {row['objectivePriorType']} prior\")\n",
    "\n",
    "# load problem\n",
    "importer = pypesto.petab.PetabImporter(petab_problem, simulator_type=\"amici\")\n",
    "factory = importer.create_objective_creator()\n",
    "\n",
    "model = factory.create_model(verbose=False)\n",
    "amici_predictor = factory.create_predictor()\n",
    "amici_predictor.amici_objective.amici_solver.setAbsoluteTolerance(1e-8)\n",
    "\n",
    "# Creating the pypesto problem from PEtab\n",
    "pypesto_problem = importer.create_problem(\n",
    "    startpoint_kwargs={\"check_fval\": True, \"check_grad\": True}\n",
    ")"
   ],
   "id": "6bc21d5dc9ed9ad7",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:petab.v1.lint:Checking model...\n",
      "INFO:petab.v1.lint:Checking measurement table...\n",
      "INFO:petab.v1.lint:Checking condition table...\n",
      "INFO:petab.v1.lint:Checking observable table...\n",
      "INFO:petab.v1.lint:Checking parameter table...\n",
      "WARNING:petab.v1.lint:Visualization table not available. Skipping.\n",
      "INFO:petab.v1.lint:PEtab format check completed successfully.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:52.249974Z",
     "start_time": "2025-09-22T08:36:52.244718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def prior():\n",
    "    lb = petab_problem.parameter_df['lowerBound'].values\n",
    "    ub = petab_problem.parameter_df['upperBound'].values\n",
    "    param_names_id = petab_problem.parameter_df.index.values\n",
    "    param_scale = petab_problem.parameter_df['parameterScale'].values\n",
    "    if 'objectivePriorType' in petab_problem.parameter_df.columns:\n",
    "        prior_type = petab_problem.parameter_df['objectivePriorType'].values\n",
    "    else:\n",
    "        prior_type = [np.nan] * len(param_names_id)\n",
    "    estimate_param = petab_problem.parameter_df['estimate'].values\n",
    "\n",
    "    prior_dict = {}\n",
    "    for i, name in enumerate(param_names_id):\n",
    "        if estimate_param[i] == 0:\n",
    "            prior_dict[name] = petab_problem.parameter_df['nominalValue'].values[i]  # linear space\n",
    "        elif prior_type[i] == 'uniform':  # linear space\n",
    "            prior_dict[name] = np.random.uniform(low=lb[i], high=ub[i])\n",
    "        elif prior_type[i] == 'parameterScaleUniform' or pd.isna(prior_type[i]):\n",
    "            # scale bounds to scaled space\n",
    "            lb_scaled_i = scale_values(lb[i], param_scale[i])\n",
    "            ub_scaled_i = scale_values(ub[i], param_scale[i])\n",
    "            val = np.random.uniform(low=lb_scaled_i, high=ub_scaled_i)\n",
    "            # scale to linear space\n",
    "            prior_dict[name] = values_to_linear_scale(val, param_scale[i])\n",
    "        elif prior_type[i] == 'parameterScaleNormal':\n",
    "            mean, std = petab_problem.parameter_df['objectivePriorParameters'].values[i].split(';')\n",
    "            lb_scaled_i = scale_values(lb[i], param_scale[i])\n",
    "            ub_scaled_i = scale_values(ub[i], param_scale[i])\n",
    "            a, b = (lb_scaled_i - float(mean)) / float(std), (ub_scaled_i - float(mean)) / float(std)\n",
    "            rv = stats.truncnorm.rvs(loc=float(mean), scale=float(std), a=a, b=b)\n",
    "            # scale to linear space\n",
    "            prior_dict[name] = values_to_linear_scale(rv, param_scale[i])\n",
    "        elif prior_type[i] == 'normal':\n",
    "            mean, std = petab_problem.parameter_df['objectivePriorParameters'].values[i].split(';')\n",
    "            a, b = (lb[i] - float(mean)) / float(std), (ub[i] - float(mean)) / float(std)\n",
    "            rv = stats.truncnorm.rvs(loc=float(mean), scale=float(std), a=a, b=b)\n",
    "            prior_dict[name] = rv\n",
    "        elif prior_type[i] == 'laplace':\n",
    "            loc, scale = petab_problem.parameter_df['objectivePriorParameters'].values[i].split(';')\n",
    "            for t in range(10):\n",
    "                rv = np.random.laplace(loc=float(loc), scale=float(scale))\n",
    "                if lb[i] <= rv <= ub[i]:  # sample from truncated laplace\n",
    "                    break\n",
    "            prior_dict[name] = rv\n",
    "        else:\n",
    "            raise ValueError(\"Unknown prior type:\", prior_type[i])\n",
    "        # scale params and make list\n",
    "        prior_dict[name] = np.array([scale_values(prior_dict[name], param_scale[i])])\n",
    "\n",
    "    # prepare variables for simulation\n",
    "    x = np.array([prior_dict[name][0] for name in pypesto_problem.x_names])\n",
    "    prior_dict['amici_params'] = x  # scaled parameters for amici\n",
    "    return prior_dict\n",
    "\n",
    "def simulator_amici(amici_params):\n",
    "    pred = amici_predictor(amici_params)  # expect amici_params to be scaled\n",
    "    sim, failed = amici_pred_to_array(pred, amici_params,\n",
    "                                      factory=factory, petab_problem=petab_problem, pypesto_problem=pypesto_problem)\n",
    "    return dict(sim_data=sim, sim_failed=failed)"
   ],
   "id": "d478fd3d90b5da5f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:53.829204Z",
     "start_time": "2025-09-22T08:36:52.253266Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prior_sample = prior()\n",
    "test = simulator_amici(prior_sample['amici_params'])\n",
    "test['sim_data'].shape, prior_sample['amici_params'].shape, np.nansum(test['sim_data'])"
   ],
   "id": "815a2fa50947e5f0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((714, 38), (72,), 9860.631272676585)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:53.844667Z",
     "start_time": "2025-09-22T08:36:53.842885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # plot prior\n",
    "# n_rows = len(pypesto_problem.x_names) // 6\n",
    "# n_cols = int(np.ceil(len(pypesto_problem.x_names) / n_rows))\n",
    "# fig, axs = plt.subplots(n_rows, n_cols, figsize=(2*n_rows, 2*n_cols), layout='constrained')\n",
    "# axs = axs.flatten()\n",
    "# samples = [prior() for i in range(1000)]\n",
    "# for i, name in enumerate(pypesto_problem.x_names):\n",
    "#     samples_i = np.array([s[name] for s in samples]).flatten()\n",
    "#     axs[i].hist(samples_i, density=True)\n",
    "#     axs[i].set_title(name)\n",
    "#     # axs[i].axvline(scale_values(petab_problem.parameter_df['nominalValue'][i],\n",
    "#     #                              petab_problem.parameter_df['parameterScale'][i]), color='red', linestyle='--')\n",
    "#     # axs[i].axvline(scale_values(petab_problem.parameter_df['lowerBound'][i],\n",
    "#     #                             petab_problem.parameter_df['parameterScale'][i]), color='blue', linestyle='--')\n",
    "#     # axs[i].axvline(scale_values(petab_problem.parameter_df['upperBound'][i],\n",
    "#     #                             petab_problem.parameter_df['parameterScale'][i]), color='blue', linestyle='--')\n",
    "# plt.show()"
   ],
   "id": "8b4598746c13ef4",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:53.852214Z",
     "start_time": "2025-09-22T08:36:53.847970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def run_mcmc(petab_problem, pypesto_problem, true_params=None, n_optimization_starts=0, n_chains=10, n_samples=10000,\n",
    "             n_procs=10, verbose=False) -> Union[pypesto.result.Result, tuple[pypesto.result.Result, petab.Problem, pypesto.Problem]]:\n",
    "    _petab_problem = deepcopy(petab_problem)\n",
    "    if true_params is None:\n",
    "        # use true data\n",
    "        pass\n",
    "    else:\n",
    "        # this is needed to create a new measurement df and recompile the problem for amici\n",
    "        pred = amici_predictor(true_params)\n",
    "        _, failed = amici_pred_to_array(pred, true_params,\n",
    "                                      factory=factory, petab_problem=petab_problem, pypesto_problem=pypesto_problem)\n",
    "        if failed:\n",
    "            print(\"Simulation failed for true parameters\")\n",
    "            return None, None, None\n",
    "        _measurement_df = factory.prediction_to_petab_measurement_df(pred) # to create new measurement df\n",
    "        _measurement_df = apply_noise_to_data(_measurement_df, true_params, field='measurement',\n",
    "                                              pypesto_problem=pypesto_problem, petab_problem=_petab_problem)\n",
    "        _petab_problem.measurement_df = _measurement_df\n",
    "    _importer = pypesto.petab.PetabImporter(_petab_problem, simulator_type=\"amici\")\n",
    "    _factory = _importer.create_objective_creator()\n",
    "    _model = _factory.create_model(verbose=False)\n",
    "\n",
    "    _pypesto_problem = _importer.create_problem(\n",
    "        startpoint_kwargs={\"check_fval\": True, \"check_grad\": True}\n",
    "    )\n",
    "\n",
    "    if isinstance(_pypesto_problem.objective, pypesto.objective.AggregatedObjective):\n",
    "        _pypesto_problem.objective._objectives[0].amici_solver.setAbsoluteTolerance(1e-8)\n",
    "        #_pypesto_problem.objective._objectives[0].amici_solver.setSensitivityMethod(amici.SensitivityMethod.adjoint)\n",
    "    else:\n",
    "        _pypesto_problem.objective.amici_solver.setAbsoluteTolerance(1e-8)\n",
    "        #_pypesto_problem.objective.amici_solver.setSensitivityMethod(amici.SensitivityMethod.adjoint)\n",
    "\n",
    "    if n_optimization_starts == 0:\n",
    "        print(\"Skipping optimization, sample start points for chains from prior\")\n",
    "        _result = None\n",
    "        x0 = [_pypesto_problem.get_reduced_vector(prior()['amici_params']) for _ in range(n_chains)]\n",
    "    else:\n",
    "        # do the optimization\n",
    "        _result = optimize.minimize(\n",
    "            problem=_pypesto_problem,\n",
    "            optimizer=optimize.FidesOptimizer(verbose=0),\n",
    "            #optimizer=optimize.ScipyOptimizer(method='L-BFGS-B'),\n",
    "            n_starts=n_optimization_starts,\n",
    "            engine=pypesto.engine.MultiProcessEngine(n_procs=n_procs) if n_procs > 1 else None,\n",
    "            progress_bar=verbose\n",
    "        )\n",
    "        x0 = [_pypesto_problem.get_reduced_vector(_result.optimize_result.x[0])]\n",
    "        if x0[0] is None:\n",
    "            print(\"Warning: x0 contains nan, replace with prior sample\")\n",
    "            x0[0] = _pypesto_problem.get_reduced_vector(prior()['amici_params'])\n",
    "        x0 += [_pypesto_problem.get_reduced_vector(prior()['amici_params']) for _ in range(n_chains - 1)]\n",
    "\n",
    "    _sampler = sample.AdaptiveParallelTemperingSampler(\n",
    "        internal_sampler=sample.AdaptiveMetropolisSampler(\n",
    "            options=dict(decay_constant=0.7, threshold_sample=2000)\n",
    "        ),\n",
    "        n_chains=n_chains,\n",
    "        options=dict(show_progress=verbose)\n",
    "    )\n",
    "\n",
    "    _result = sample.sample(\n",
    "        problem=_pypesto_problem,\n",
    "        n_samples=n_samples,\n",
    "        sampler=_sampler,\n",
    "        result=_result,\n",
    "        x0=x0\n",
    "    )\n",
    "    sample.geweke_test(_result)\n",
    "\n",
    "    if true_params is None:\n",
    "        return _result\n",
    "    return _result, _petab_problem, _pypesto_problem"
   ],
   "id": "39067b9bf1fc3e6",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:53.858902Z",
     "start_time": "2025-09-22T08:36:53.856833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_mcmc_posterior_samples(res):\n",
    "    burn_in = sample.geweke_test(res)\n",
    "    if burn_in == res.sample_result.trace_x.shape[1]:\n",
    "        print(\"Warning: All samples are considered burn-in.\")\n",
    "        _samples = res.sample_result.trace_x[0]  # only use first chain\n",
    "    else:\n",
    "        _samples = res.sample_result.trace_x[0, burn_in:]  # only use first chain\n",
    "    #_samples = pypesto_problem.get_full_vector(_samples)\n",
    "    #scales = petab_problem.parameter_df.loc[res.problem.x_names, 'parameterScale'].values\n",
    "    #_samples = values_to_linear_scale(_samples, scales)\n",
    "    return _samples"
   ],
   "id": "74f951d5b884ee3d",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:36:56.047043Z",
     "start_time": "2025-09-22T08:36:53.862949Z"
    }
   },
   "cell_type": "code",
   "source": [
    "n_optimization_starts = 0\n",
    "test_params = prior()\n",
    "#print(test_params)\n",
    "new_result, new_petab_problem, new_pypesto_problem = run_mcmc(\n",
    "    petab_problem=petab_problem,\n",
    "    pypesto_problem=pypesto_problem,\n",
    "    true_params=test_params['amici_params'],\n",
    "    n_optimization_starts=n_optimization_starts,\n",
    "    n_samples=1e3,\n",
    "    n_procs=n_cpus,\n",
    "    n_chains=3,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "if n_optimization_starts > 0:\n",
    "    visualize.waterfall(new_result, size=(6, 4))\n",
    "    ax = visualize.parameters(new_result, size=(6, 25))\n",
    "    visualize_optimized_model_fit(petab_problem=new_petab_problem, result=new_result, pypesto_problem=new_pypesto_problem);\n",
    "\n",
    "#print(test_params['amici_params']-new_result.optimize_result.x[0])"
   ],
   "id": "62ba1a556342abed",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[8]\u001B[39m\u001B[32m, line 4\u001B[39m\n\u001B[32m      2\u001B[39m test_params = prior()\n\u001B[32m      3\u001B[39m \u001B[38;5;66;03m#print(test_params)\u001B[39;00m\n\u001B[32m----> \u001B[39m\u001B[32m4\u001B[39m new_result, new_petab_problem, new_pypesto_problem = \u001B[43mrun_mcmc\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m      5\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpetab_problem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpetab_problem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      6\u001B[39m \u001B[43m    \u001B[49m\u001B[43mpypesto_problem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpypesto_problem\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      7\u001B[39m \u001B[43m    \u001B[49m\u001B[43mtrue_params\u001B[49m\u001B[43m=\u001B[49m\u001B[43mtest_params\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mamici_params\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      8\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_optimization_starts\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_optimization_starts\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m      9\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_samples\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m1e3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     10\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_procs\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn_cpus\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m    \u001B[49m\u001B[43mn_chains\u001B[49m\u001B[43m=\u001B[49m\u001B[32;43m3\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m     12\u001B[39m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[43m=\u001B[49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\n\u001B[32m     13\u001B[39m \u001B[43m)\u001B[49m\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_optimization_starts > \u001B[32m0\u001B[39m:\n\u001B[32m     16\u001B[39m     visualize.waterfall(new_result, size=(\u001B[32m6\u001B[39m, \u001B[32m4\u001B[39m))\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 10\u001B[39m, in \u001B[36mrun_mcmc\u001B[39m\u001B[34m(petab_problem, pypesto_problem, true_params, n_optimization_starts, n_chains, n_samples, n_procs, verbose)\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m      8\u001B[39m     \u001B[38;5;66;03m# this is needed to create a new measurement df and recompile the problem for amici\u001B[39;00m\n\u001B[32m      9\u001B[39m     pred = amici_predictor(true_params)\n\u001B[32m---> \u001B[39m\u001B[32m10\u001B[39m     _, failed = \u001B[43mamici_pred_to_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrue_params\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m     11\u001B[39m \u001B[43m                                  \u001B[49m\u001B[43mfactory\u001B[49m\u001B[43m=\u001B[49m\u001B[43mfactory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpetab_problem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpetab_problem\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpypesto_problem\u001B[49m\u001B[43m=\u001B[49m\u001B[43mpypesto_problem\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m failed:\n\u001B[32m     13\u001B[39m         \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mSimulation failed for true parameters\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/case_study2/petab_helper.py:128\u001B[39m, in \u001B[36mamici_pred_to_array\u001B[39m\u001B[34m(pred, params, factory, pypesto_problem, petab_problem)\u001B[39m\n\u001B[32m    126\u001B[39m failed = \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[32m    127\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m--> \u001B[39m\u001B[32m128\u001B[39m     sim_df = \u001B[43mfactory\u001B[49m\u001B[43m.\u001B[49m\u001B[43mprediction_to_petab_simulation_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpred\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    129\u001B[39m     sim_df = apply_noise_to_data(sim_df, params, field=\u001B[33m'\u001B[39m\u001B[33msimulation\u001B[39m\u001B[33m'\u001B[39m,\n\u001B[32m    130\u001B[39m                                  pypesto_problem=pypesto_problem, petab_problem=petab_problem)\n\u001B[32m    131\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pypesto/petab/objective_creator.py:593\u001B[39m, in \u001B[36mAmiciObjectiveCreator.prediction_to_petab_simulation_df\u001B[39m\u001B[34m(self, prediction, predictor)\u001B[39m\n\u001B[32m    582\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprediction_to_petab_simulation_df\u001B[39m(\n\u001B[32m    583\u001B[39m     \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    584\u001B[39m     prediction: PredictionResult,\n\u001B[32m    585\u001B[39m     predictor: AmiciPredictor = \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[32m    586\u001B[39m ) -> pd.DataFrame:\n\u001B[32m    587\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    588\u001B[39m \u001B[33;03m    See :meth:`prediction_to_petab_measurement_df`.\u001B[39;00m\n\u001B[32m    589\u001B[39m \n\u001B[32m    590\u001B[39m \u001B[33;03m    Except a PEtab simulation dataframe is created, i.e. the measurement\u001B[39;00m\n\u001B[32m    591\u001B[39m \u001B[33;03m    column label is adjusted.\u001B[39;00m\n\u001B[32m    592\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m593\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mprediction_to_petab_measurement_df\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    594\u001B[39m \u001B[43m        \u001B[49m\u001B[43mprediction\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpredictor\u001B[49m\n\u001B[32m    595\u001B[39m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m.rename(columns={petab.MEASUREMENT: petab.SIMULATION})\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pypesto/petab/objective_creator.py:580\u001B[39m, in \u001B[36mAmiciObjectiveCreator.prediction_to_petab_measurement_df\u001B[39m\u001B[34m(self, prediction, predictor)\u001B[39m\n\u001B[32m    577\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m predictor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    578\u001B[39m     model = predictor.amici_objective.amici_model\n\u001B[32m--> \u001B[39m\u001B[32m580\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrdatas_to_measurement_df\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrdatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pypesto/petab/objective_creator.py:521\u001B[39m, in \u001B[36mAmiciObjectiveCreator.rdatas_to_measurement_df\u001B[39m\u001B[34m(self, rdatas, model, verbose)\u001B[39m\n\u001B[32m    517\u001B[39m     model = \u001B[38;5;28mself\u001B[39m.create_model(verbose=verbose)\n\u001B[32m    519\u001B[39m measurement_df = \u001B[38;5;28mself\u001B[39m.petab_problem.measurement_df\n\u001B[32m--> \u001B[39m\u001B[32m521\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mamici\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpetab\u001B[49m\u001B[43m.\u001B[49m\u001B[43msimulations\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrdatas_to_measurement_df\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    522\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrdatas\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmeasurement_df\u001B[49m\n\u001B[32m    523\u001B[39m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/amici/petab/simulations.py:457\u001B[39m, in \u001B[36mrdatas_to_measurement_df\u001B[39m\u001B[34m(rdatas, model, measurement_df)\u001B[39m\n\u001B[32m    448\u001B[39m cur_measurement_df = petab.get_rows_for_condition(\n\u001B[32m    449\u001B[39m     measurement_df, condition\n\u001B[32m    450\u001B[39m )\n\u001B[32m    452\u001B[39m \u001B[38;5;66;03m# iterate over entries for the given condition\u001B[39;00m\n\u001B[32m    453\u001B[39m \u001B[38;5;66;03m# note: this way we only generate a dataframe entry for every\u001B[39;00m\n\u001B[32m    454\u001B[39m \u001B[38;5;66;03m# row that existed in the original dataframe. if we want to\u001B[39;00m\n\u001B[32m    455\u001B[39m \u001B[38;5;66;03m# e.g. have also timepoints non-existent in the original file,\u001B[39;00m\n\u001B[32m    456\u001B[39m \u001B[38;5;66;03m# we need to instead iterate over the rdata['y'] entries\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m457\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrow\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mcur_measurement_df\u001B[49m\u001B[43m.\u001B[49m\u001B[43miterrows\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m    458\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# copy row\u001B[39;49;00m\n\u001B[32m    459\u001B[39m \u001B[43m    \u001B[49m\u001B[43mrow_sim\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdeepcopy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrow\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    461\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# extract simulated measurement value\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pandas/core/frame.py:1559\u001B[39m, in \u001B[36mDataFrame.iterrows\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1557\u001B[39m using_cow = using_copy_on_write()\n\u001B[32m   1558\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(\u001B[38;5;28mself\u001B[39m.index, \u001B[38;5;28mself\u001B[39m.values):\n\u001B[32m-> \u001B[39m\u001B[32m1559\u001B[39m     s = \u001B[43mklass\u001B[49m\u001B[43m(\u001B[49m\u001B[43mv\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m=\u001B[49m\u001B[43mk\u001B[49m\u001B[43m)\u001B[49m.__finalize__(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m   1560\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m using_cow \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._mgr.is_single_block:\n\u001B[32m   1561\u001B[39m         s._mgr.add_references(\u001B[38;5;28mself\u001B[39m._mgr)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pandas/core/series.py:593\u001B[39m, in \u001B[36mSeries.__init__\u001B[39m\u001B[34m(self, data, index, dtype, name, copy, fastpath)\u001B[39m\n\u001B[32m    590\u001B[39m         data = SingleArrayManager.from_array(data, index)\n\u001B[32m    592\u001B[39m NDFrame.\u001B[34m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, data)\n\u001B[32m--> \u001B[39m\u001B[32m593\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mname\u001B[49m = name\n\u001B[32m    594\u001B[39m \u001B[38;5;28mself\u001B[39m._set_axis(\u001B[32m0\u001B[39m, index)\n\u001B[32m    596\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m original_dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m is_pandas_object \u001B[38;5;129;01mand\u001B[39;00m data_dtype == np.object_:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pandas/core/generic.py:6339\u001B[39m, in \u001B[36mNDFrame.__setattr__\u001B[39m\u001B[34m(self, name, value)\u001B[39m\n\u001B[32m   6336\u001B[39m \u001B[38;5;66;03m# if this fails, go on to more involved attribute setting\u001B[39;00m\n\u001B[32m   6337\u001B[39m \u001B[38;5;66;03m# (note that this matches __getattr__, above).\u001B[39;00m\n\u001B[32m   6338\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._internal_names_set:\n\u001B[32m-> \u001B[39m\u001B[32m6339\u001B[39m     \u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m.\u001B[49m\u001B[34;43m__setattr__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalue\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   6340\u001B[39m \u001B[38;5;28;01melif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._metadata:\n\u001B[32m   6341\u001B[39m     \u001B[38;5;28mobject\u001B[39m.\u001B[34m__setattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name, value)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/PyCharm Projects/diffusion-experiments/.venv/lib/python3.12/site-packages/pandas/core/series.py:784\u001B[39m, in \u001B[36mSeries.name\u001B[39m\u001B[34m(self, value)\u001B[39m\n\u001B[32m    736\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    737\u001B[39m \u001B[33;03m    Return the name of the Series.\u001B[39;00m\n\u001B[32m    738\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    780\u001B[39m \u001B[33;03m    'Even Numbers'\u001B[39;00m\n\u001B[32m    781\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m    782\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._name\n\u001B[32m--> \u001B[39m\u001B[32m784\u001B[39m \u001B[38;5;129m@name\u001B[39m.setter\n\u001B[32m    785\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mname\u001B[39m(\u001B[38;5;28mself\u001B[39m, value: Hashable) -> \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    786\u001B[39m     validate_all_hashable(value, error_name=\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m.name\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m    787\u001B[39m     \u001B[38;5;28mobject\u001B[39m.\u001B[34m__setattr__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33m_name\u001B[39m\u001B[33m\"\u001B[39m, value)\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# n_optimization_starts = 20\n",
    "# result = run_mcmc(\n",
    "#     petab_problem=petab_problem,\n",
    "#     pypesto_problem=pypesto_problem,\n",
    "#     n_optimization_starts=n_optimization_starts,\n",
    "#     n_samples=1e3\n",
    "# )\n",
    "#\n",
    "# if n_optimization_starts > 0:\n",
    "#     visualize.waterfall(result, size=(6, 4))\n",
    "#     visualize.parameters(result, size=(6, 25))\n",
    "#     visualize_optimized_model_fit(petab_problem=petab_problem, result=result, pypesto_problem=pypesto_problem);"
   ],
   "id": "82b4a81a42d5475c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#ax = visualize.sampling_parameter_traces(result, size=(20, 20), full_trace=False, use_problem_bounds=False);\n",
    "#visualize.sampling_scatter(result, size=(13, 6));"
   ],
   "id": "8e7d158c84562a1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# BayesFlow workflow",
   "id": "2471c34692a6d37c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.427890Z",
     "start_time": "2025-09-22T08:36:58.890597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "simulator = bf.make_simulator([prior, simulator_amici])\n",
    "simulator.sample(2).keys(), simulator.sample(2)['sim_data'].shape"
   ],
   "id": "79a7fafc4a732243",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['Bacmax_typeIDT1_ExpID1', 'Bacmax_typeIDT1_ExpID2', 'Bacmax_typeIDT1_ExpID3', 'Bacmax_typeIDT1_ExpID4', 'Bacmax_typeIDT1_ExpID5', 'Bacmax_typeIDT1_ExpID6', 'Bacmax_typeIDT3_ExpID1', 'Bacmax_typeIDT3_ExpID2', 'Bacmax_typeIDT3_ExpID3', 'Bacmax_typeIDT3_ExpID4', 'Bacmax_typeIDT3_ExpID5', 'Bacmax_typeIDT3_ExpID6', 'Bacmax_typeIDT5_ExpID1', 'Bacmax_typeIDT5_ExpID2', 'Bacmax_typeIDT5_ExpID3', 'Bacmax_typeIDT5_ExpID4', 'Bacmax_typeIDT5_ExpID5', 'Bacmax_typeIDT5_ExpID6', 'Bacmax_typeIDwt_ExpID4', 'beta_typeIDT1_ExpID1', 'beta_typeIDT1_ExpID2', 'beta_typeIDT1_ExpID3', 'beta_typeIDT1_ExpID4', 'beta_typeIDT1_ExpID5', 'beta_typeIDT1_ExpID6', 'beta_typeIDT3_ExpID1', 'beta_typeIDT3_ExpID2', 'beta_typeIDT3_ExpID3', 'beta_typeIDT3_ExpID4', 'beta_typeIDT3_ExpID5', 'beta_typeIDT3_ExpID6', 'beta_typeIDT5_ExpID1', 'beta_typeIDT5_ExpID2', 'beta_typeIDT5_ExpID3', 'beta_typeIDT5_ExpID4', 'beta_typeIDT5_ExpID5', 'beta_typeIDT5_ExpID6', 'beta_typeIDwt_ExpID4', 'init_Bac', 'kdegi_typeIDT1', 'kdegi_typeIDT3', 'kdegi_typeIDT5', 'kdegi_typeIDwt', 'kdim_typeIDT1', 'kdim_typeIDT3', 'kdim_typeIDT5', 'kdim_typeIDwt', 'ksyn_typeIDT1', 'ksyn_typeIDT3', 'ksyn_typeIDT5', 'ksyn_typeIDwt', 'sd_Bacnorm', 'sd_IndconcNormRange', 'tau_typeIDT1_ExpID1', 'tau_typeIDT1_ExpID2', 'tau_typeIDT1_ExpID3', 'tau_typeIDT1_ExpID4', 'tau_typeIDT1_ExpID5', 'tau_typeIDT1_ExpID6', 'tau_typeIDT3_ExpID1', 'tau_typeIDT3_ExpID2', 'tau_typeIDT3_ExpID3', 'tau_typeIDT3_ExpID4', 'tau_typeIDT3_ExpID5', 'tau_typeIDT3_ExpID6', 'tau_typeIDT5_ExpID1', 'tau_typeIDT5_ExpID2', 'tau_typeIDT5_ExpID3', 'tau_typeIDT5_ExpID4', 'tau_typeIDT5_ExpID5', 'tau_typeIDT5_ExpID6', 'tau_typeIDwt_ExpID4', 'amici_params', 'sim_data', 'sim_failed']),\n",
       " (2, 714, 38))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.433654Z",
     "start_time": "2025-09-22T08:37:05.432217Z"
    }
   },
   "cell_type": "code",
   "source": [
    "num_training_sets = 512*64\n",
    "num_validation_sets = 100"
   ],
   "id": "35657d5e8c718c77",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.459189Z",
     "start_time": "2025-09-22T08:37:05.456491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "@delayed\n",
    "def sample_and_simulate():\n",
    "    \"\"\"Single iteration of sampling and simulation\"\"\"\n",
    "    prior_sample = prior()\n",
    "    test = simulator_amici(prior_sample['amici_params'])\n",
    "\n",
    "    # Combine both dictionaries\n",
    "    result = {**prior_sample, **test}\n",
    "    return result\n",
    "\n",
    "def simulate_parallel(n_samples):\n",
    "    \"\"\"Parallel sampling and simulation\"\"\"\n",
    "    results = Parallel(n_jobs=n_cpus, verbose=100)(\n",
    "        sample_and_simulate() for _ in range(n_samples)\n",
    "    )\n",
    "    results_dict = defaultdict(list)\n",
    "\n",
    "    for r in results:\n",
    "        for key, value in r.items():\n",
    "            results_dict[key].append(value)\n",
    "    for key, value_list in results_dict.items():\n",
    "        results_dict[key] = np.array(value_list)\n",
    "    return results_dict"
   ],
   "id": "817a213c704ef666",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.527920Z",
     "start_time": "2025-09-22T08:37:05.475302Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if os.path.exists(f\"{storage}validation_data_petab_{problem_name}.pkl\"):\n",
    "    with open(f'{storage}validation_data_petab_{problem_name}.pkl', 'rb') as f:\n",
    "        validation_data = pickle.load(f)\n",
    "    try:\n",
    "        with open(f'{storage}training_data_petab_{problem_name}.pkl', 'rb') as f:\n",
    "            training_data = pickle.load(f)\n",
    "    except FileNotFoundError:\n",
    "        training_data = None\n",
    "        print(\"Training data not found\")\n",
    "else:\n",
    "    training_data = simulate_parallel(num_training_sets)\n",
    "    validation_data = simulate_parallel(num_validation_sets)\n",
    "\n",
    "    with open(f'{storage}training_data_petab_{problem_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(training_data, f)\n",
    "    with open(f'{storage}validation_data_petab_{problem_name}.pkl', 'wb') as f:\n",
    "        pickle.dump(validation_data, f)\n",
    "\n",
    "# remove failed simulations\n",
    "if not training_data is None:\n",
    "    train_mask = ~training_data['sim_failed']\n",
    "    for key in training_data.keys():\n",
    "        training_data[key] = training_data[key][train_mask]\n",
    "    print(f\"Failed Training data: {np.sum(~train_mask)} / {len(train_mask)}\")\n",
    "val_mask = ~validation_data['sim_failed']\n",
    "for key in validation_data.keys():\n",
    "    validation_data[key] = validation_data[key][val_mask]\n",
    "print(f\"Failed Validation data: {np.sum(~val_mask)} / {len(val_mask)}\")\n",
    "\n",
    "test_mean = np.nanmean(np.log(validation_data['sim_data']+1), axis=(0,1), keepdims=True)\n",
    "test_std = np.nanstd(np.log(validation_data['sim_data']+1), axis=(0,1), keepdims=True)\n",
    "print(validation_data['sim_data'].shape)"
   ],
   "id": "db8aaf92772d55a5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data not found\n",
      "Failed Validation data: 0 / 100\n",
      "(100, 714, 38)\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.535175Z",
     "start_time": "2025-09-22T08:37:05.532039Z"
    }
   },
   "cell_type": "code",
   "source": [
    "param_names = [name for i, name in enumerate(pypesto_problem.x_names) if i in pypesto_problem.x_free_indices]\n",
    "lbs = np.array([lb for i, lb in enumerate(petab_problem.lb_scaled) if i in pypesto_problem.x_free_indices])\n",
    "ubs = np.array([ub for i, ub in enumerate(petab_problem.ub_scaled) if i in pypesto_problem.x_free_indices])\n",
    "\n",
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .drop('amici_params')  # only used for simulation\n",
    "    .to_array()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .concatenate(param_names, into=\"inference_variables\")\n",
    "    .constrain(\"inference_variables\", lower=lbs, upper=ubs, inclusive='both')  # after concatenate such that we can apply an array as constraint\n",
    "\n",
    "    .as_time_series(\"sim_data\")\n",
    "    .log(\"sim_data\", p1=True)\n",
    "    #.standardize(\"sim_data\", mean=test_mean, std=test_std)\n",
    "    #.nan_to_num(\"sim_data\", default_value=-3.0)\n",
    "    .rename(\"sim_data\", \"summary_variables\")\n",
    ")"
   ],
   "id": "84f74d0e7c75651a",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.541677Z",
     "start_time": "2025-09-22T08:37:05.539941Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# # check how the distributions look like\n",
    "# test_params = adapter.forward(validation_data)['inference_variables']\n",
    "#\n",
    "# n_rows = len(param_names) // 6\n",
    "# n_cols = int(np.ceil(len(param_names) / n_rows))\n",
    "# fig, ax = plt.subplots(n_rows, n_cols, figsize=(2*n_rows, 2*n_cols), layout='constrained')\n",
    "# ax = ax.flatten()\n",
    "# for i, name in enumerate(param_names):\n",
    "#     samples = test_params[:, i]\n",
    "#     ax[i].hist(samples, density=True)\n",
    "#     ax[i].set_title(name)\n",
    "# plt.show()"
   ],
   "id": "6d79fc2eac8185eb",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.558523Z",
     "start_time": "2025-09-22T08:37:05.545120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# check how the data distribution looks like (disable nan_to_num in adapter to see nans)\n",
    "test_data = adapter.forward(validation_data)['summary_variables']\n",
    "# n_features = test_data.shape[-1]\n",
    "#\n",
    "# n_rows = n_features // 5\n",
    "# n_cols = int(np.ceil(n_features / n_rows))\n",
    "# fig, ax = plt.subplots(nrows=n_rows, ncols=n_cols, figsize=(2*n_rows, 2*n_cols))\n",
    "# ax = ax.flatten()\n",
    "# for i in range(n_features):\n",
    "#     ax[i].hist(test_data[:, :, i].flatten(), density=True)\n",
    "# plt.show()"
   ],
   "id": "d13f79cb2d51a9d1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.572004Z",
     "start_time": "2025-09-22T08:37:05.565676Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# print some stats about the data\n",
    "print('Minimum', np.min(test_data))\n",
    "print('Maximum', np.max(test_data))\n",
    "print('Mean', np.mean(test_data))\n",
    "print('Standard Deviation', np.std(test_data))\n",
    "print('Nan Values', np.isnan(test_data).sum())"
   ],
   "id": "db94aa20d5ed36c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum 0.0\n",
      "Maximum 4.2376857\n",
      "Mean 0.30746585\n",
      "Standard Deviation 0.41734025\n",
      "Nan Values 0\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.578650Z",
     "start_time": "2025-09-22T08:37:05.575755Z"
    }
   },
   "cell_type": "code",
   "source": "from model_settings import EPOCHS, BATCH_SIZE, MODELS, NUM_SAMPLES_INFERENCE, SAMPLER_SETTINGS",
   "id": "220da44d055c7a33",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.588044Z",
     "start_time": "2025-09-22T08:37:05.585899Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_name = list(MODELS.keys())[-1]\n",
    "conf_tuple = MODELS[model_name]\n",
    "print(model_name)"
   ],
   "id": "6a0293b5f73232bc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'diffusion_cosine_noise'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:05.785979Z",
     "start_time": "2025-09-22T08:37:05.591758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = bf.BasicWorkflow(\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    summary_network=bf.networks.FusionTransformer(summary_dim=len(param_names)*2),  # FusionTransformer\n",
    "    inference_network=conf_tuple[0](**conf_tuple[1]),\n",
    "    standardize='all'\n",
    ")"
   ],
   "id": "8567adc22e0fbc09",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:23.563290Z",
     "start_time": "2025-09-22T08:37:05.789931Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model_path = f'{storage}petab_benchmark_diffusion_model_{problem_name}_{model_name}.keras'\n",
    "if not os.path.exists(model_path):\n",
    "    history = workflow.fit_offline(\n",
    "        training_data,\n",
    "        epochs=EPOCHS,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        validation_data=validation_data,\n",
    "        verbose=2\n",
    "    )\n",
    "    #workflow.approximator.save(model_path)\n",
    "else:\n",
    "    workflow.approximator = keras.models.load_model(model_path)"
   ],
   "id": "410e6d32cba52fff",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:bayesflow:Fitting on dataset instance of OfflineDataset.\n",
      "INFO:bayesflow:Building on a test batch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 10s - 10s/step - loss: 22.5965 - val_loss: 13.5632\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "diagnostics_plots = workflow.plot_default_diagnostics(test_data=validation_data, num_samples=NUM_SAMPLES_INFERENCE,\n",
    "                                                      calibration_ecdf_kwargs={\"difference\": True, 'stacked': True})\n",
    "#for k in diagnostics_plots.keys():\n",
    "#    diagnostics_plots[k].savefig(f\"{storage}petab_benchmark_{problem_name}_{model_name}_{k}.pdf\")"
   ],
   "id": "3894672c0c7ed821",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-22T08:37:32.031323Z",
     "start_time": "2025-09-22T08:37:23.619582Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if model_name.startswith('diffusion'):\n",
    "    for solver_name in SAMPLER_SETTINGS:\n",
    "        diagnostics = workflow.compute_default_diagnostics(test_data=validation_data, num_samples=NUM_SAMPLES_INFERENCE, approximator_kwargs=SAMPLER_SETTINGS[solver_name])\n",
    "        print(solver_name)\n",
    "        print(diagnostics.median(axis=1))\n",
    "        print('\\n')"
   ],
   "id": "8fb68f418664d6c4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'start_time': 1.0, 'stop_time': 0.0, 'method': 'rk45', 'steps': 100}\n",
      "ode\n",
      "NRMSE                    1.935771\n",
      "Posterior Contraction    1.000000\n",
      "Calibration Error        0.500000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "{'start_time': 1.0, 'stop_time': 0.0, 'method': 'euler_maruyama', 'steps': 100}\n",
      "sde\n",
      "NRMSE                    1.935771\n",
      "Posterior Contraction    1.000000\n",
      "Calibration Error        0.500000\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "{'start_time': 1.0, 'stop_time': 0.0, 'method': 'euler_maruyama', 'steps': 100, 'corrector_steps': 1}\n",
      "sde-pc\n",
      "NRMSE                    1.935771\n",
      "Posterior Contraction    1.000000\n",
      "Calibration Error        0.500000\n",
      "dtype: float64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "416fa380abd57171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# MCMC sampling for comparison",
   "id": "e6f768baf9a64371"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def run_mcmc_single(petab_prob, pypesto_prob, true_params, n_starts, n_mcmc_samples, n_final_samples, n_chains):\n",
    "    import amici\n",
    "    import logging\n",
    "    amici.swig_wrappers.logger.setLevel(logging.CRITICAL)\n",
    "    pypesto.logging.log(level=logging.ERROR, name=\"pypesto.petab\", console=True)\n",
    "\n",
    "    try:\n",
    "        r, _, _ = run_mcmc(\n",
    "            petab_problem=petab_prob,\n",
    "            pypesto_problem=pypesto_prob,\n",
    "            true_params=true_params,\n",
    "            n_optimization_starts=n_starts,\n",
    "            n_samples=n_mcmc_samples,\n",
    "            n_chains=n_chains,\n",
    "            n_procs=1\n",
    "        )\n",
    "    except np.linalg.LinAlgError as e:\n",
    "        print(\"LinAlgError during MCMC:\", e)\n",
    "        return np.full((n_final_samples, len(pypesto_prob.x_free_indices)), np.nan)\n",
    "\n",
    "    if r is None:\n",
    "        return np.full((n_final_samples, len(pypesto_prob.x_free_indices)), np.nan)\n",
    "\n",
    "    ps = get_mcmc_posterior_samples(r)\n",
    "    # num_samples random samples from posterior\n",
    "    idx = np.random.choice(ps.shape[0], size=n_final_samples)\n",
    "    return ps[idx]"
   ],
   "id": "80cea9fd8aa5d13f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "mcmc_path = f'{storage}mcmc_samples_{problem_name}.pkl'\n",
    "if os.path.exists(mcmc_path):\n",
    "    with open(mcmc_path, 'rb') as f:\n",
    "        mcmc_posterior_samples = pickle.load(f)\n",
    "else:\n",
    "    mcmc_posterior_samples = Parallel(n_jobs=n_cpus, verbose=10)(\n",
    "        delayed(run_mcmc_single)(\n",
    "            petab_prob=petab_problem,\n",
    "            pypesto_prob=pypesto_problem,\n",
    "            true_params=params,\n",
    "            n_starts=10,\n",
    "            n_mcmc_samples=1e5,\n",
    "            n_final_samples=num_samples,\n",
    "            n_chains=10\n",
    "        ) for params in validation_data['amici_params']\n",
    "    )\n",
    "    mcmc_posterior_samples = np.array(mcmc_posterior_samples)\n",
    "\n",
    "    with open(mcmc_path, 'wb') as f:\n",
    "        pickle.dump(mcmc_posterior_samples, f)\n",
    "mcmc_mask = ~np.isnan(mcmc_posterior_samples.sum(axis=(1,2)))"
   ],
   "id": "3c6844de0597c037",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig = bf.diagnostics.recovery(\n",
    "    estimates=mcmc_posterior_samples[mcmc_mask * val_mask],\n",
    "    targets=pypesto_problem.get_reduced_vector(validation_data['amici_params'].T).T[mcmc_mask],\n",
    "    variable_names=param_names,\n",
    ")\n",
    "fig.savefig(f\"{storage}petab_benchmark_{problem_name}_mcmc_recovery.png\")\n",
    "\n",
    "fig = bf.diagnostics.calibration_ecdf(\n",
    "    estimates=mcmc_posterior_samples[mcmc_mask * val_mask],\n",
    "    targets=pypesto_problem.get_reduced_vector(validation_data['amici_params'].T).T[mcmc_mask],\n",
    "    variable_names=param_names,\n",
    "    difference=True,\n",
    "    stacked=True\n",
    ")\n",
    "fig.savefig(f\"{storage}petab_benchmark_{problem_name}_mcmc_calibration.png\")"
   ],
   "id": "65eb5cdc2255a29a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5265fe7d01d58685",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
