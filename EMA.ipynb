{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "os.environ['KERAS_BACKEND'] = 'torch'  # todo: not working for jax\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import keras\n",
    "from keras import ops\n",
    "\n",
    "import bayesflow as bf"
   ],
   "id": "93d855858bef6645",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def theta_prior():\n",
    "    theta = np.random.uniform(-1, 1, 2)\n",
    "    return dict(theta=theta)\n",
    "\n",
    "def forward_model(theta):\n",
    "    alpha = np.random.uniform(-np.pi / 2, np.pi / 2)\n",
    "    r = np.random.normal(0.1, 0.01)\n",
    "    x1 = -np.abs(theta[0] + theta[1]) / np.sqrt(2) + r * np.cos(alpha) + 0.25\n",
    "    x2 = (-theta[0] + theta[1]) / np.sqrt(2) + r * np.sin(alpha)\n",
    "    return dict(x=np.array([x1, x2]))\n",
    "\n",
    "simulator = bf.make_simulator([theta_prior, forward_model])"
   ],
   "id": "25fe0511bf632d99",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    # convert any non-arrays to numpy arrays\n",
    "    .to_array()\n",
    "    # convert from numpy's default float64 to deep learning friendly float32\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    # rename the variables to match the required approximator inputs\n",
    "    .rename(\"theta\", \"inference_variables\")\n",
    "    .rename(\"x\", \"inference_conditions\")\n",
    ")"
   ],
   "id": "f942772e48df34d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_training_batches = 512\n",
    "num_validation_sets = 100\n",
    "batch_size = 64\n",
    "epochs = 25"
   ],
   "id": "9843dde201617047",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "training_data = simulator.sample(num_training_batches * batch_size)\n",
    "validation_data = simulator.sample(num_validation_sets)"
   ],
   "id": "2bfa9c9b8c295cf7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# in 1% of the training steps, we update the EMA\n",
    "ema_update_every = int(epochs * num_training_batches * 0.01)\n",
    "print(f\"EMA update every {ema_update_every} steps of {num_training_batches* epochs} total training steps ({ema_update_every / (num_training_batches* epochs)*100}%).\")"
   ],
   "id": "6c259c193291d00e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class EMA(keras.callbacks.Callback):\n",
    "    def __init__(self, update_every, beta=0.9, use_for_validation=False):  # todo: use_for_validation seems to be not working\n",
    "        super().__init__()\n",
    "        self.beta = float(beta)\n",
    "        self.update_every = int(update_every)\n",
    "        self.use_for_validation = bool(use_for_validation)\n",
    "        self._shadow = None\n",
    "        self._backup = None\n",
    "        self._step = 0\n",
    "        self._n_vars = 0\n",
    "        print(f\"EMA model update every {update_every} steps.\")\n",
    "\n",
    "    def _snapshot(self, v):\n",
    "        t = ops.convert_to_tensor(v)\n",
    "        try:\n",
    "            t = ops.stop_gradient(t)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "        return t\n",
    "\n",
    "    def _init_slots_from_tv(self, tv):\n",
    "        self._shadow = [self._snapshot(v) for v in tv]\n",
    "        self._backup = [None] * len(tv)\n",
    "        self._n_vars = len(tv)\n",
    "\n",
    "    def _ensure_slots(self):\n",
    "        tv = self.model.trainable_variables\n",
    "        if self._shadow is None or self._n_vars != len(tv):\n",
    "            self._init_slots_from_tv(tv)\n",
    "        return tv\n",
    "\n",
    "    def on_train_begin(self, logs=None):\n",
    "        self._step = 0\n",
    "        self._ensure_slots()\n",
    "\n",
    "    def on_train_batch_end(self, batch, logs=None):\n",
    "        self._step += 1\n",
    "        if self._step % self.update_every != 0:\n",
    "            return\n",
    "        tv = self._ensure_slots()\n",
    "        b = self.beta\n",
    "        new_shadow = []\n",
    "        for s, v in zip(self._shadow, tv):\n",
    "            v_now = self._snapshot(v)\n",
    "            if ops.dtype(s) != ops.dtype(v_now):\n",
    "                v_now = ops.cast(v_now, ops.dtype(s))\n",
    "            new_shadow.append(b * s + (1.0 - b) * v_now)\n",
    "        self._shadow = new_shadow\n",
    "\n",
    "    def _swap_to_shadow(self):\n",
    "        tv = self._ensure_slots()\n",
    "        for i, v in enumerate(tv):\n",
    "            self._backup[i] = self._snapshot(v)\n",
    "            w = self._shadow[i]\n",
    "            if ops.dtype(w) != v.dtype:\n",
    "                w = ops.cast(w, v.dtype)\n",
    "            v.assign(w)\n",
    "\n",
    "    def _swap_from_shadow(self):\n",
    "        tv = self._ensure_slots()\n",
    "        for i, v in enumerate(tv):\n",
    "            v.assign(self._backup[i])\n",
    "        self._backup = [None] * len(tv)\n",
    "\n",
    "    def on_test_begin(self, logs=None):\n",
    "        if not self.use_for_validation:\n",
    "            return\n",
    "        self._swap_to_shadow()\n",
    "\n",
    "    def on_test_end(self, logs=None):\n",
    "        if not self.use_for_validation:\n",
    "            return\n",
    "        self._swap_from_shadow()\n"
   ],
   "id": "8d4d0c23278dd16d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "ema_cb = EMA(update_every=ema_update_every)\n",
    "\n",
    "workflow_diffusion_ema = bf.BasicWorkflow(\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    #inference_network=bf.networks.DiffusionModel()\n",
    "    inference_network=bf.networks.CouplingFlow()\n",
    ")\n",
    "\n",
    "history_ema = workflow_diffusion_ema.fit_offline(\n",
    "    data=training_data,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_data,\n",
    "    callbacks=[ema_cb]\n",
    ")\n",
    "#workflow_diffusion_ema.approximator.save(filepath='test.keras')"
   ],
   "id": "519751d89774b73c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# assume ema_cb is your callback with _swap_to_shadow and _swap_from_shadow\n",
    "def save_both(model, ema_cb, path_noema=\"model_noema.keras\", path_ema=\"model_ema.keras\"):\n",
    "    # save non EMA\n",
    "    model.save(path_noema)\n",
    "    # save EMA\n",
    "    ema_cb._swap_to_shadow()\n",
    "    try:\n",
    "        model.save(path_ema)\n",
    "    finally:\n",
    "        ema_cb._swap_from_shadow()\n",
    "\n",
    "save_both(workflow_diffusion_ema.approximator, ema_cb)\n",
    "model_noema = keras.saving.load_model(\"model_noema.keras\")\n",
    "model_ema   = keras.saving.load_model(\"model_ema.keras\")"
   ],
   "id": "bd5758b6e209b5e8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "workflow_diffusion_ema.approximator = model_noema\n",
    "workflow_diffusion_ema.plot_default_diagnostics(test_data=validation_data, num_samples=100, calibration_ecdf_kwargs={\"difference\": True});"
   ],
   "id": "dfdc6cc79d4a1683",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "workflow_diffusion_ema.approximator = model_ema\n",
    "workflow_diffusion_ema.plot_default_diagnostics(test_data=validation_data, num_samples=100, calibration_ecdf_kwargs={\"difference\": True});"
   ],
   "id": "f8ab435da876283b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "workflow_diffusion = bf.BasicWorkflow(\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    #inference_network=bf.networks.DiffusionModel()\n",
    "    inference_network=bf.networks.CouplingFlow()\n",
    ")\n",
    "\n",
    "history = workflow_diffusion.fit_offline(\n",
    "    data=training_data,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_data=validation_data,\n",
    ")"
   ],
   "id": "cccb5a6bc20ead44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#workflow_diffusion.approximator.save(\"model.keras\")\n",
    "#workflow_diffusion.approximator = keras.saving.load_model(\"model.keras\")"
   ],
   "id": "a00139f5f53e5fa6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "workflow_diffusion.plot_default_diagnostics(test_data=validation_data, num_samples=100, calibration_ecdf_kwargs={\"difference\": True});",
   "id": "46fc41a0c45ca405",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Obtain samples from the approximators (can also use the workflows' methods)\n",
    "workflows = [\n",
    "    workflow_diffusion,\n",
    "    workflow_diffusion_ema,\n",
    "    workflow_diffusion_ema,\n",
    "]\n",
    "names = [\n",
    "    \"Standard Model\",\n",
    "    \"Model with EMA (disabled)\",\n",
    "    \"Model with EMA\"\n",
    "]\n",
    "colors = [\"#153c7a\", \"#7a1515\", \"#8c1740\"]"
   ],
   "id": "a7010268a0ec2bfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set the number of posterior draws you want to get\n",
    "num_samples = 1000\n",
    "\n",
    "# Obtain samples from amortized posterior\n",
    "conditions = {\"x\": np.array([[0.0, 0.0]]).astype(\"float32\")}\n",
    "\n",
    "# Prepare figure\n",
    "f, axes = plt.subplots(1, len(workflows), figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "for i, (ax, w, name, color) in enumerate(zip(axes, workflows, names, colors)):\n",
    "    np.random.seed(0)\n",
    "    if i == 1:\n",
    "        w.approximator = model_noema\n",
    "    elif i == 2:\n",
    "        w.approximator = model_ema\n",
    "    print(w.compute_default_diagnostics(test_data=validation_data, num_samples=100))\n",
    "\n",
    "    # Obtain samples\n",
    "    samples = w.approximator.sample(conditions=conditions, num_samples=num_samples)[\"theta\"]\n",
    "\n",
    "    # Plot samples\n",
    "    ax.scatter(samples[0, :, 0], samples[0, :, 1], color=color, alpha=0.75, s=0.5)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_title(f\"{name}\", fontsize=16)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlim([-0.5, 0.5])\n",
    "    ax.set_ylim([-0.5, 0.5])\n",
    "    ax.set_xlabel(r\"$\\theta_1$\", fontsize=15)\n",
    "    ax.set_ylabel(r\"$\\theta_2$\", fontsize=15)\n",
    "\n",
    "plt.show()"
   ],
   "id": "21786678e6a2cd47",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Prepare figure\n",
    "colors = [\"#153c7a\", \"#7a1515\", \"#8c1740\"]\n",
    "conditions = {\"x\": np.array([[0.0, 0.0]]).astype(\"float32\")}\n",
    "num_samples = 1000\n",
    "\n",
    "f, axes = plt.subplots(1, 2, figsize=(12, 6), layout=\"constrained\")\n",
    "\n",
    "for i, (ax, name, color) in enumerate(zip(axes, ['Model', 'Loaded Model'], colors)):\n",
    "    # Obtain samples\n",
    "    samples = workflow_diffusion.approximator.sample(conditions=conditions, num_samples=num_samples)[\"theta\"]\n",
    "\n",
    "    # Plot samples\n",
    "    ax.scatter(samples[0, :, 0], samples[0, :, 1], color=color, alpha=0.75, s=0.5)\n",
    "    sns.despine(ax=ax)\n",
    "    ax.set_title(f\"{name}\", fontsize=16)\n",
    "    ax.grid(alpha=0.3)\n",
    "    ax.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    ax.set_xlim([-0.5, 0.5])\n",
    "    ax.set_ylim([-0.5, 0.5])\n",
    "    ax.set_xlabel(r\"$\\theta_1$\", fontsize=15)\n",
    "    ax.set_ylabel(r\"$\\theta_2$\", fontsize=15)\n",
    "\n",
    "    workflow_diffusion.approximator.save(\"model.keras\")\n",
    "    workflow_diffusion.approximator = keras.saving.load_model(\"model.keras\")\n",
    "\n",
    "plt.show()"
   ],
   "id": "d42c0c2a8f0ada84",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4b987424cf156813",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
