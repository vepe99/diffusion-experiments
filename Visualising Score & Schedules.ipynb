{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "009b6adf",
   "metadata": {},
   "source": "# Visualising Score & Schedules of the Diffusion Model\n"
  },
  {
   "cell_type": "code",
   "id": "d5f88a59",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "if \"KERAS_BACKEND\" not in os.environ:\n",
    "    os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "else:\n",
    "    print(f\"Using '{os.environ['KERAS_BACKEND']}' backend\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0551e46f",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "import bayesflow as bf"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Simulator<a class=\"anchor\" id=\"simulator\"></a>",
   "id": "c63b26ba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def theta_prior():\n",
    "    theta = np.random.uniform(-1, 1, 2)\n",
    "    return dict(theta=theta)\n",
    "\n",
    "def forward_model(theta):\n",
    "    alpha = np.random.uniform(-np.pi / 2, np.pi / 2)\n",
    "    r = np.random.normal(0.1, 0.01)\n",
    "    x1 = -np.abs(theta[0] + theta[1]) / np.sqrt(2) + r * np.cos(alpha) + 0.25\n",
    "    x2 = (-theta[0] + theta[1]) / np.sqrt(2) + r * np.sin(alpha)\n",
    "    return dict(x=np.array([x1, x2]))"
   ],
   "id": "f761b142a0e1da66",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "4b89c861527c13b8",
   "metadata": {},
   "source": [
    "simulator = bf.make_simulator([theta_prior, forward_model])"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "5c9c2dc70f53d103",
   "metadata": {},
   "source": [
    "adapter = (\n",
    "    bf.adapters.Adapter()\n",
    "    .to_array()\n",
    "    .convert_dtype(\"float64\", \"float32\")\n",
    "    .rename(\"theta\", \"inference_variables\")\n",
    "    .rename(\"x\", \"inference_conditions\")\n",
    ")\n",
    "adapter"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Training",
   "id": "35291b6d847c2fb1"
  },
  {
   "cell_type": "code",
   "id": "39cb5a1c9824246f",
   "metadata": {},
   "source": [
    "num_training_batches = 512\n",
    "num_validation_sets = 300\n",
    "batch_size = 64\n",
    "epochs = 50"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9dee7252ef99affa",
   "metadata": {},
   "source": [
    "training_data = simulator.sample(num_training_batches * batch_size)\n",
    "validation_data = simulator.sample(num_validation_sets)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "noise_schedule = ['cosine', 'edm'][1]\n",
    "diffusion_model = bf.networks.DiffusionModel(\n",
    "    noise_schedule=noise_schedule\n",
    ")"
   ],
   "id": "a30c09e65f39fb16",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "96ca6ffa",
   "metadata": {},
   "source": [
    "diffusion_model_workflow = bf.BasicWorkflow(\n",
    "    simulator=simulator,\n",
    "    adapter=adapter,\n",
    "    inference_network=diffusion_model,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "0f496bda",
   "metadata": {},
   "source": [
    "history = diffusion_model_workflow.fit_offline(\n",
    "    training_data, \n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size, \n",
    "    validation_data=validation_data,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e2fbe42f-b6e8-45f3-a53a-4015fb84e78f",
   "metadata": {},
   "source": [
    "%%time\n",
    "samples_s = diffusion_model_workflow.sample(num_samples=1000, method=\"euler_maruyama\",\n",
    "                                           conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)})\n",
    "plt.scatter(samples_s[\"theta\"][0, :, 0], samples_s[\"theta\"][0, :, 1], alpha=0.75, s=0.5, label=\"euler maruyama\")\n",
    "plt.gca().set_aspect(\"equal\", adjustable=\"box\")\n",
    "plt.xlim([-0.5, 0.5])\n",
    "plt.ylim([-0.5, 0.5])\n",
    "\n",
    "samples = diffusion_model_workflow.sample(num_samples=1000,method=\"euler\",\n",
    "                                          conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)})\n",
    "plt.scatter(samples[\"theta\"][0, :, 0], samples[\"theta\"][0, :, 1], alpha=0.75, s=0.5, label=\"euler\")\n",
    "plt.xlim([-0.5, 0.5])\n",
    "plt.ylim([-0.5, 0.5])\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualizing the Trajectory",
   "id": "6ba22a899ba3a5e8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def euler_backward_like(workflow, conditions, t_start=1.0, t_end=0.0, steps=100, num_samples=1, stochastic_solver=False):\n",
    "    # conditions must always have shape (batch_size, ..., dims)\n",
    "    conditions_prep = diffusion_model_workflow.approximator._prepare_data(conditions)['inference_conditions']\n",
    "    batch_size = keras.ops.shape(conditions_prep)[0]\n",
    "    inference_conditions = keras.ops.expand_dims(conditions_prep, axis=1)\n",
    "    inference_conditions = keras.ops.broadcast_to(\n",
    "                    inference_conditions, (batch_size, num_samples, *keras.ops.shape(inference_conditions)[2:])\n",
    "    )\n",
    "\n",
    "    dt = (t_end - t_start) / steps  # negative if integrating toward 0\n",
    "    x = diffusion_model_workflow.inference_network.base_distribution.sample((1, num_samples))\n",
    "    t = float(t_start)\n",
    "\n",
    "    traj = []\n",
    "    vels = []\n",
    "    for k in range(steps):\n",
    "        traj.append(x.numpy())\n",
    "        v_curr = workflow.inference_network.velocity(\n",
    "            xz=x, time=t, conditions=inference_conditions, stochastic_solver=stochastic_solver, training=False\n",
    "        )\n",
    "        if stochastic_solver:\n",
    "            diff_curr = workflow.inference_network.diffusion_term(\n",
    "                xz=x, time=t, training=False\n",
    "            )\n",
    "            noise = keras.random.normal(keras.ops.shape(x), dtype=keras.ops.dtype(x)) * np.sqrt(np.abs(dt))\n",
    "            x = x + diff_curr * noise\n",
    "\n",
    "        x = x + dt * v_curr\n",
    "        t = t + dt\n",
    "        vels.append(v_curr.numpy())\n",
    "\n",
    "    traj = np.stack(traj, axis=0)      # shape [steps+1, batch, num_samples, dims]\n",
    "    vels = np.stack(vels, axis=0)      # shape [steps,   batch, num_samples, dims]\n",
    "    times = np.linspace(t_start, t_end, steps+1, dtype=np.float32)\n",
    "\n",
    "    traj =  workflow.approximator.standardize_layers[\"inference_variables\"](traj, forward=False)\n",
    "    return traj, vels, times\n",
    "\n",
    "# run\n",
    "traj, vels, times = euler_backward_like(\n",
    "    diffusion_model_workflow, conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)}, steps=100, stochastic_solver=False\n",
    ")\n",
    "traj, vels = traj[:, 0, 0], vels[:, 0, 0]  # take first batch item\n",
    "\n",
    "# pick first item in batch and first sample\n",
    "vel_norm = np.linalg.norm(vels, axis=-1)\n",
    "\n",
    "# trajectory plot\n",
    "plt.figure()\n",
    "plt.plot(traj[:, 0], traj[:, 1], linewidth=2)\n",
    "plt.scatter(traj[0, 0], traj[0, 1], s=60, marker='o', label='start')   # start\n",
    "plt.scatter(traj[-1, 0], traj[-1, 1], s=60, marker='x', label='end') # end\n",
    "plt.title(\"Trajectory\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# velocity over time\n",
    "plt.figure()\n",
    "plt.plot(times[:-1], vel_norm, linewidth=2)\n",
    "plt.title(\"Velocity norm over time\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"||v||\")\n",
    "plt.show()"
   ],
   "id": "5252221790198aee",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure()\n",
    "for i in range(20):\n",
    "    traj, vels, times = euler_backward_like(\n",
    "        diffusion_model_workflow, conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)}, steps=50, stochastic_solver=False\n",
    "    )\n",
    "    traj, vels = traj[:, 0, 0], vels[:, 0, 0]  # take first batch item\n",
    "\n",
    "    # trajectory plot\n",
    "    plt.plot(traj[:, 0], traj[:, 1], linewidth=2, color='blue')\n",
    "    plt.scatter(traj[0, 0], traj[0, 1], s=60, marker='x', label='start' if i == 0 else None, color='blue', alpha=0.5) # start\n",
    "    #plt.scatter(traj[-1, 0], traj[-1, 1], s=60, marker='o', label='end' if i == 0 else None, color='blue', alpha=0.5) # end\n",
    "\n",
    "plt.scatter(samples[\"theta\"][0, :, 0], samples[\"theta\"][0, :, 1], alpha=0.5, s=0.5, color='red', label='samples')\n",
    "plt.title(f\"Trajectory {noise_schedule.title()}\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "e8fc20e1f0f1a0f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def moving_average(x, w=10):\n",
    "    return np.convolve(x, np.ones(w)/w, mode=\"valid\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(10):\n",
    "    traj, vels, times = euler_backward_like(\n",
    "        diffusion_model_workflow, conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)}, steps=50, stochastic_solver=True\n",
    "    )\n",
    "    traj, vels = traj[:, 0, 0], vels[:, 0, 0]  # take first batch item\n",
    "\n",
    "    # trajectory plot\n",
    "    #plt.plot(traj[:, 0], traj[:, 1], linewidth=2, color='blue')\n",
    "    #plt.scatter(traj[0, 0], traj[0, 1], s=60, marker='o', label='start' if i == 0 else None, color='blue', alpha=0.2) # start\n",
    "    #plt.scatter(traj[-1, 0], traj[-1, 1], s=60, marker='x', label='end' if i == 0 else None, color='blue', alpha=0.2) # end\n",
    "    x_smooth = moving_average(traj[:,0])\n",
    "    y_smooth = moving_average(traj[:,1])\n",
    "    plt.plot(x_smooth, y_smooth, linewidth=2, color='blue')\n",
    "    plt.scatter(x_smooth[0], y_smooth[0], s=60, marker='x', label='start' if i == 0 else None, color='blue', alpha=0.2) # start\n",
    "    #plt.scatter(x_smooth[-1], y_smooth[-1], s=60, marker='o', label='end' if i == 0 else None, color='blue', alpha=0.2) # end\n",
    "\n",
    "plt.scatter(samples_s[\"theta\"][0, :, 0], samples_s[\"theta\"][0, :, 1], alpha=0.2, s=0.5, color='red', label='samples')\n",
    "plt.title(f\"Trajectory {noise_schedule.title()}, stochastic sampler (moving average)\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.axis('equal')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "919f85804ce14634",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def velocity_field_plot(workflow, conditions, times, traj, stochastic_solver, grid_limits=(-3,3), grid_points=20, name=None):\n",
    "    # grid\n",
    "    x = np.linspace(grid_limits[0], grid_limits[1], grid_points)\n",
    "    y = np.linspace(grid_limits[0], grid_limits[1], grid_points)\n",
    "    X, Y = np.meshgrid(x, y)\n",
    "    grid = np.stack([X, Y], axis=-1)  # [grid_points, grid_points, 2]\n",
    "    grid = grid.reshape(-1, 2)[None]  # [1, grid_points*grid_points, 2]\n",
    "\n",
    "    grid_transf = workflow.approximator.standardize_layers[\"inference_variables\"](grid.reshape(-1, 2), forward=False)\n",
    "    grid_transf = np.asarray(grid_transf)\n",
    "    XY_transf = grid_transf.reshape(grid_points, grid_points, 2) # [G, G, 2]\n",
    "    X_transf = XY_transf[..., 0]\n",
    "    Y_transf = XY_transf[..., 1]\n",
    "\n",
    "    # conditions must always have shape (batch_size, ..., dims)\n",
    "    conditions_prep = diffusion_model_workflow.approximator._prepare_data(conditions)['inference_conditions']\n",
    "    batch_size = keras.ops.shape(conditions_prep)[0]\n",
    "    inference_conditions = keras.ops.expand_dims(conditions_prep, axis=1)\n",
    "    inference_conditions = keras.ops.broadcast_to(\n",
    "                    inference_conditions, (batch_size, grid_points*grid_points, *keras.ops.shape(inference_conditions)[2:])\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, len(times), figsize=(5*len(times), 5), layout='constrained', sharex=True, sharey=True, squeeze=False)\n",
    "\n",
    "    for i, t in enumerate(times):\n",
    "        # expand to shape [batch, num_samples, dim]\n",
    "        v = workflow.inference_network.velocity(\n",
    "            xz=grid, time=float(t), conditions=inference_conditions, stochastic_solver=stochastic_solver, training=False\n",
    "        ).numpy()\n",
    "        v = v[0, :, :2]  # [num_points, 2]\n",
    "\n",
    "        U = v[:,0].reshape(grid_points, grid_points)\n",
    "        V = v[:,1].reshape(grid_points, grid_points)\n",
    "\n",
    "        ax = axes[0, i]\n",
    "        ax.quiver(X_transf, Y_transf, U, -V, angles=\"xy\", label=\"velocity field\", alpha=0.5)\n",
    "        ax.plot(traj[:,0], traj[:,1], color=\"red\", linewidth=2, label=\"trajectory\")\n",
    "        ax.scatter(traj[0,0], traj[0,1], color=\"green\", s=60, label=\"start\")\n",
    "        ax.scatter(traj[-1,0], traj[-1,1], color=\"black\", s=60, label=\"end\")\n",
    "\n",
    "        if name is not None:\n",
    "            ax.set_title(f\"{name} time={t:.2f}\")\n",
    "        else:\n",
    "            ax.set_title(f\"time={t:.2f}\")\n",
    "        ax.set_xlim((X_transf.min(), X_transf.max()))\n",
    "        ax.set_ylim((Y_transf.min(), Y_transf.max()))\n",
    "        ax.legend()\n",
    "    plt.show()"
   ],
   "id": "4a9a5b4a34ec9c29",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "traj, vels, times = euler_backward_like(\n",
    "    diffusion_model_workflow, conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)}, steps=100, stochastic_solver=False\n",
    ")\n",
    "traj, vels = traj[:, 0, 0], vels[:, 0, 0]  # take first batch item\n",
    "velocity_field_plot(\n",
    "    diffusion_model_workflow,\n",
    "    conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)},\n",
    "    times=[1.0, 0.5, 0.0],\n",
    "    traj=traj,\n",
    "    stochastic_solver=False,\n",
    "    name=f\"deterministic sampling, {noise_schedule},\"\n",
    ")\n",
    "\n",
    "traj, vels, times = euler_backward_like(\n",
    "    diffusion_model_workflow, conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)}, steps=100, stochastic_solver=True\n",
    ")\n",
    "traj, vels = traj[:, 0, 0], vels[:, 0, 0]  # take first batch item\n",
    "velocity_field_plot(\n",
    "    diffusion_model_workflow,\n",
    "    conditions={\"x\":np.array([[0.0, 0.0]], dtype=np.float32)},\n",
    "    times=[1.0, 0.5, 0.0],\n",
    "    traj=traj,\n",
    "    stochastic_solver=True,\n",
    "    name=f\"stochastic sampling, {noise_schedule},\"\n",
    ")"
   ],
   "id": "99f4443291310b3c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "f1282ade83d40ecd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "from bayesflow.networks.diffusion_model.schedules import EDMNoiseSchedule, CosineNoiseSchedule, NoiseSchedule",
   "id": "ef6ddb2da13bf8b1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class FlowMatching(NoiseSchedule):\n",
    "    def __init__(self):\n",
    "        super().__init__(name=\"Flow Matching Schedule\", variance_type=\"preserving\", weighting=None)\n",
    "\n",
    "    def get_log_snr(self, t, training):\n",
    "        \"\"\"Get the log signal-to-noise ratio (lambda) for a given diffusion time.\"\"\"\n",
    "        return 2 * keras.ops.log((1-t)/t)\n",
    "\n",
    "    def get_t_from_log_snr(self, log_snr_t, training: bool):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def derivative_log_snr(self, log_snr_t, training):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_weights_for_snr(self, log_snr_t):\n",
    "        return 1 + keras.ops.exp(-log_snr_t) + 2*keras.ops.exp(-log_snr_t / 2)"
   ],
   "id": "2428482878b57571",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "edm = EDMNoiseSchedule()\n",
    "cosine = CosineNoiseSchedule()\n",
    "edm.name = \"EDM Schedule\"\n",
    "cosine.name = \"Cosine Schedule\"\n",
    "fm = FlowMatching()\n",
    "\n",
    "time = keras.ops.linspace(0.0, 1.0, 10000)\n",
    "colors = [\"blue\", \"orange\", \"green\"]\n",
    "schedules = [edm, cosine, fm]"
   ],
   "id": "fc4614be04485301",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize=(6,3), layout='constrained')\n",
    "for i, schedule in enumerate(schedules):\n",
    "    training_schedule = schedule.get_log_snr(time, training=True).numpy()\n",
    "    inference_schedule = schedule.get_log_snr(time, training=False).numpy()\n",
    "\n",
    "    if (training_schedule != inference_schedule).all():\n",
    "        plt.plot(time, training_schedule, label=f\"{schedule.name} Training\", color=colors[i])\n",
    "        plt.plot(time, inference_schedule, label=f\"{schedule.name} Inference\", linestyle=\"--\", color=colors[i])\n",
    "    else:\n",
    "        plt.plot(time, training_schedule, label=f\"{schedule.name} Training & Inference\", color=colors[i])\n",
    "plt.legend()\n",
    "plt.ylabel(r\"log SNR $\\lambda$\")\n",
    "plt.xlabel(\"time\")\n",
    "plt.show()"
   ],
   "id": "e348df0a230f5b38",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots(ncols=2, figsize=(6,3), layout='constrained', sharey=True, sharex=True)\n",
    "for i, schedule in enumerate(schedules):\n",
    "    training_schedule = schedule.get_log_snr(time[1:-1], training=True)\n",
    "    training_weights = schedule.get_weights_for_snr(training_schedule).numpy()\n",
    "    ax[0].hist(training_schedule, density=True, color=colors[i], label=f\"{schedule.name}\", alpha=0.7, bins=20)\n",
    "\n",
    "    log_snr = np.random.choice(training_schedule, p=training_weights / training_weights.sum(), replace=True, size=10000)\n",
    "    ax[1].hist(log_snr, density=True, color=colors[i], label=f\"{schedule.name}\", alpha=0.7, bins=20)\n",
    "\n",
    "for a in ax:\n",
    "    a.legend(loc=\"upper right\")\n",
    "    a.set_xlabel(r\"log SNR $\\lambda$\")\n",
    "ax[0].set_ylabel(r\"Density\")\n",
    "ax[0].set_title(\"Raw Schedules\")\n",
    "ax[1].set_title(\"With Weighting Functions\")\n",
    "plt.show()"
   ],
   "id": "270140709f77afcf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "sech = lambda x: 1 / np.cosh(x)"
   ],
   "id": "57d2e479eea5109",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "lambda_t = np.linspace(-15, 15, 100)\n",
    "fm_w =  np.exp(-lambda_t/2)\n",
    "edm_w = norm.pdf(lambda_t, loc=2.4, scale=2.4) * (np.exp(-lambda_t) + 1**2)\n",
    "cosine_w = sech(lambda_t / 2)\n",
    "\n",
    "plt.plot(lambda_t, fm_w / max(fm_w), label='flow matching')\n",
    "plt.plot(lambda_t, edm_w / max(edm_w), label='edm')\n",
    "plt.plot(lambda_t, cosine_w / max(cosine_w), label='cosine')\n",
    "plt.xlabel(r\"log SNR $\\lambda$\")\n",
    "plt.ylabel(\"Implied Weighting Function\")\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "e829c47f0990389f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d608a60aa5df3a3d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
